{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuner\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import random\n",
    "random.seed(12345)\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import io\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1234)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "import csv\n",
    "from plotly.graph_objs import *\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#keras.metrics.custom_metrics = {'accurate_rate':accurate_rate,'accuracy':accuracy}\n",
    "model = load_model('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=[]\n",
    "mae=[]\n",
    "for i in range(10):\n",
    "    sample_index=np.unique(np.random.randint(93,size=15))[:10]\n",
    "    predicts=model.predict(X_[sample_index])\n",
    "    predicts[sampleweights[sample_index]==0,:]=0\n",
    "    y_real=Y[sample_index]\n",
    "    y_real=y_real.reshape(200)\n",
    "    predicts=predicts.reshape(200)[y_real!=0]\n",
    "    y_real=y_real[y_real!=0]\n",
    "    mse.append(np.mean(np.power(np.abs(predicts-y_real),2)))\n",
    "    mae.append(np.mean(np.abs(predicts-y_real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16359518999651648\n",
      "0.284948459259441\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mse))\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.307164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_on_batch(X_,Y,sample_weight=sampleweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=model.predict(X_)\n",
    "predicts[sampleweights==0,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_=Y.reshape(20*93)\n",
    "predicts_=predicts.reshape(20*93)[Y_!=0]\n",
    "Y_=Y_[Y_!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predicts_-Y_)\n",
    "print(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18214375913999925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "diff=np.power(np.abs(predicts_-Y_),2)\n",
    "#diff=diff.reshape(1860)\n",
    "print(np.mean(diff))\n",
    "plt.hist(diff, bins='auto')\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30048047967288727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff=np.power(np.abs(predicts_-Y_),1)\n",
    "#diff=diff.reshape(1860)\n",
    "print(np.mean(diff))\n",
    "plt.hist(diff, bins='auto')\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader2=csv.reader(open('LSTM_data_disciplines.csv','r'))\n",
    "reader3=csv.reader(open('LSTM_data_journals.csv','r'))\n",
    "reader4=csv.reader(open('LSTM_JIF.csv','r'))\n",
    "reader5=csv.reader(open('LSTM_data_2_count.csv','r'))\n",
    "reader6=csv.reader(open('LSTM_coindex.csv','r'))\n",
    "reader1=csv.reader(open('LSTM_data_2_portion.csv','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discipline_dic={}\n",
    "for line in reader2:\n",
    "  discipline_dic[line[1]]=int(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(discipline_dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_dic={}\n",
    "for line in reader3:\n",
    "  journals_dic[line[1]]=int(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_list=[i for i in discipline_dic.keys() if 'PSYCHOLOGY' in i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_index=[]\n",
    "for i in psy_list:\n",
    "  psy_index.append(discipline_dic[i]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=np.zeros((93,20,211))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in reader5:\n",
    "  index1=journals_dic[line[1]]-1\n",
    "  index2=int(line[0])-1997\n",
    "  index3=discipline_dic[line[2]]-1\n",
    "  X2[index1,index2,index3]=float(line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMM=X2[:,:,20]\n",
    "PSY=X2[:,:,psy_index]\n",
    "PSY=np.mean(PSY,axis=2)\n",
    "BUSINESS=X2[:,:,8]\n",
    "POL_SCI=X2[:,:,42]\n",
    "SOCIOLOGY=X2[:,:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMM=COMM.reshape((93,20,1))\n",
    "PSY=PSY.reshape((93,20,1))\n",
    "BUSINESS=BUSINESS.reshape((93,20,1))\n",
    "POL_SCI=POL_SCI.reshape((93,20,1))\n",
    "SOCIOLOGY=SOCIOLOGY.reshape((93,20,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTER=X2[:,:,np.delete(np.arange(211),[20,8,42,10]+psy_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "co=np.zeros((93,20,1))\n",
    "for line in reader6:\n",
    "  if index1 in journals_dic.keys():\n",
    "    index1=journals_dic[line[1]]-1\n",
    "    index2=int(line[0])-1997\n",
    "    co[index1,index2,0]=float(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.zeros((93,20,1))\n",
    "for line in reader4:\n",
    "  if line[2] in journals_dic.keys():\n",
    "    index1=journals_dic[line[2]]-1\n",
    "    index2=int(line[0])-1997\n",
    "    try:\n",
    "      Y[index1,index2]=float(line[3])\n",
    "    except:\n",
    "      print(line[3])\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA,NMF,TruncatedSVD\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca=[]\n",
    "for i in INTER:\n",
    "  X_pca.extend(i)\n",
    "X_pca=pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "externs=[0]*211\n",
    "for discipline in discipline_dic.keys():\n",
    "  externs[discipline_dic[discipline]-1]=discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "externs=np.delete(externs,[20,8,42,10]+psy_index)\n",
    "X_pca.columns=externs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37909048 0.1790486  0.10235857 0.07130827 0.04410595 0.03170289]\n",
      "0.8076147496221735\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_eco=X_pca.iloc[:,[0,40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.02807304],\n",
       "       [-0.02807304,  1.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(ling_eco.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.67220802, -0.27526858],\n",
       "       [-0.27526858, 11.08676131]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(ling_eco.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(list(externs).index('ECONOMICS'))\n",
    "print(list(externs).index('LINGUISTICS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.02634906,  45.23723053, -10.31023065,  20.06392128,\n",
       "          0.12034572,   1.13633154]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1097\n",
    "test2=X_pca.iloc[i:i+1]\n",
    "#test[0,40]=10\n",
    "#test2[0,0]=10\n",
    "pca.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pca.transform(X_pca)\n",
    "test=pd.DataFrame(test)\n",
    "test.columns=['Health Science','Eco/Management/Information Science','Linguistics/Anthropology','Economics/Liguistics','Cultural Studies/Education/Multidisciplinary Science','Neural/Behavioral Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Health Science</th>\n",
       "      <th>Eco/Management/Information Science</th>\n",
       "      <th>Linguistics/Anthropology</th>\n",
       "      <th>Economics/Liguistics</th>\n",
       "      <th>Cultural Studies/Education/Multidisciplinary Science</th>\n",
       "      <th>Neural/Behavioral Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>6.792594</td>\n",
       "      <td>51.425815</td>\n",
       "      <td>-12.012572</td>\n",
       "      <td>24.189839</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>1.443752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>6.026349</td>\n",
       "      <td>45.237231</td>\n",
       "      <td>-10.310231</td>\n",
       "      <td>20.063921</td>\n",
       "      <td>0.120346</td>\n",
       "      <td>1.136332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>6.269215</td>\n",
       "      <td>46.062585</td>\n",
       "      <td>-10.571448</td>\n",
       "      <td>19.775576</td>\n",
       "      <td>-2.849042</td>\n",
       "      <td>1.304156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>4.567594</td>\n",
       "      <td>38.839720</td>\n",
       "      <td>-9.881694</td>\n",
       "      <td>19.355789</td>\n",
       "      <td>-3.100812</td>\n",
       "      <td>1.945805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>4.187867</td>\n",
       "      <td>35.797508</td>\n",
       "      <td>-8.388246</td>\n",
       "      <td>14.623285</td>\n",
       "      <td>-4.044344</td>\n",
       "      <td>1.670367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>-0.079085</td>\n",
       "      <td>14.739764</td>\n",
       "      <td>-6.380511</td>\n",
       "      <td>14.055628</td>\n",
       "      <td>-0.573340</td>\n",
       "      <td>1.501939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>-0.045572</td>\n",
       "      <td>14.554470</td>\n",
       "      <td>-5.887818</td>\n",
       "      <td>12.158389</td>\n",
       "      <td>-1.525371</td>\n",
       "      <td>1.168936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>-0.009541</td>\n",
       "      <td>14.244184</td>\n",
       "      <td>-5.789508</td>\n",
       "      <td>11.814996</td>\n",
       "      <td>-1.671625</td>\n",
       "      <td>1.200214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>3.682327</td>\n",
       "      <td>30.873406</td>\n",
       "      <td>-6.907567</td>\n",
       "      <td>11.219965</td>\n",
       "      <td>-3.730409</td>\n",
       "      <td>1.459632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1.769244</td>\n",
       "      <td>0.715017</td>\n",
       "      <td>33.938674</td>\n",
       "      <td>10.930074</td>\n",
       "      <td>-1.896182</td>\n",
       "      <td>0.590886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>-0.269466</td>\n",
       "      <td>12.385016</td>\n",
       "      <td>-5.263747</td>\n",
       "      <td>10.904938</td>\n",
       "      <td>-0.836614</td>\n",
       "      <td>0.966956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2.929369</td>\n",
       "      <td>0.398331</td>\n",
       "      <td>31.385330</td>\n",
       "      <td>10.214708</td>\n",
       "      <td>-2.868285</td>\n",
       "      <td>-0.816149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>7.463085</td>\n",
       "      <td>42.621399</td>\n",
       "      <td>-6.858952</td>\n",
       "      <td>10.144553</td>\n",
       "      <td>0.374978</td>\n",
       "      <td>1.128835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2.338080</td>\n",
       "      <td>24.149025</td>\n",
       "      <td>-5.697809</td>\n",
       "      <td>9.999609</td>\n",
       "      <td>-1.981896</td>\n",
       "      <td>0.913696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2.647496</td>\n",
       "      <td>25.930554</td>\n",
       "      <td>-5.961211</td>\n",
       "      <td>9.919377</td>\n",
       "      <td>-1.513540</td>\n",
       "      <td>0.470958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>-0.731987</td>\n",
       "      <td>9.141379</td>\n",
       "      <td>-4.674560</td>\n",
       "      <td>9.869595</td>\n",
       "      <td>-0.304183</td>\n",
       "      <td>0.789829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>-0.890561</td>\n",
       "      <td>8.629187</td>\n",
       "      <td>-4.424517</td>\n",
       "      <td>9.190828</td>\n",
       "      <td>-0.225897</td>\n",
       "      <td>0.678249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2.018854</td>\n",
       "      <td>22.334911</td>\n",
       "      <td>-5.469904</td>\n",
       "      <td>9.119674</td>\n",
       "      <td>-2.016384</td>\n",
       "      <td>0.572259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.937506</td>\n",
       "      <td>3.296507</td>\n",
       "      <td>35.282706</td>\n",
       "      <td>8.974560</td>\n",
       "      <td>-3.859279</td>\n",
       "      <td>2.369375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>-0.354659</td>\n",
       "      <td>8.288146</td>\n",
       "      <td>-4.238821</td>\n",
       "      <td>8.636402</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>1.975965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0.554317</td>\n",
       "      <td>13.571790</td>\n",
       "      <td>-4.475542</td>\n",
       "      <td>8.443829</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>0.340689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>-0.144167</td>\n",
       "      <td>12.007029</td>\n",
       "      <td>-4.409145</td>\n",
       "      <td>8.213212</td>\n",
       "      <td>-1.199448</td>\n",
       "      <td>0.484501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>-0.304356</td>\n",
       "      <td>0.838410</td>\n",
       "      <td>25.221924</td>\n",
       "      <td>7.908017</td>\n",
       "      <td>-1.319624</td>\n",
       "      <td>-0.249330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>80.520674</td>\n",
       "      <td>-11.436554</td>\n",
       "      <td>-4.394274</td>\n",
       "      <td>7.792632</td>\n",
       "      <td>-3.422720</td>\n",
       "      <td>-6.224189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.247338</td>\n",
       "      <td>-0.366417</td>\n",
       "      <td>21.076897</td>\n",
       "      <td>7.488942</td>\n",
       "      <td>-2.837404</td>\n",
       "      <td>0.351668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>-0.517564</td>\n",
       "      <td>9.951490</td>\n",
       "      <td>-4.079647</td>\n",
       "      <td>7.399443</td>\n",
       "      <td>-1.744707</td>\n",
       "      <td>0.636453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>0.886581</td>\n",
       "      <td>16.428028</td>\n",
       "      <td>-4.560550</td>\n",
       "      <td>7.377625</td>\n",
       "      <td>-2.010001</td>\n",
       "      <td>0.570564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>-1.123603</td>\n",
       "      <td>-0.433629</td>\n",
       "      <td>19.532094</td>\n",
       "      <td>7.355999</td>\n",
       "      <td>-3.582294</td>\n",
       "      <td>-0.253144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-0.587886</td>\n",
       "      <td>0.077591</td>\n",
       "      <td>20.441591</td>\n",
       "      <td>7.265287</td>\n",
       "      <td>-4.254151</td>\n",
       "      <td>-0.660191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-0.477775</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>20.416913</td>\n",
       "      <td>6.999538</td>\n",
       "      <td>-1.959922</td>\n",
       "      <td>0.455390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.081706</td>\n",
       "      <td>5.950836</td>\n",
       "      <td>0.576357</td>\n",
       "      <td>-7.269881</td>\n",
       "      <td>-5.590955</td>\n",
       "      <td>-0.648175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.146572</td>\n",
       "      <td>7.926956</td>\n",
       "      <td>3.205989</td>\n",
       "      <td>-7.383675</td>\n",
       "      <td>-2.546485</td>\n",
       "      <td>-0.263868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.635166</td>\n",
       "      <td>8.495481</td>\n",
       "      <td>0.387915</td>\n",
       "      <td>-7.407908</td>\n",
       "      <td>-6.069405</td>\n",
       "      <td>-0.576852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6.006436</td>\n",
       "      <td>13.387637</td>\n",
       "      <td>4.549925</td>\n",
       "      <td>-7.745218</td>\n",
       "      <td>6.676387</td>\n",
       "      <td>-1.958899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>3.073442</td>\n",
       "      <td>14.558544</td>\n",
       "      <td>2.233110</td>\n",
       "      <td>-7.756019</td>\n",
       "      <td>-0.070212</td>\n",
       "      <td>-0.623864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.315038</td>\n",
       "      <td>6.246646</td>\n",
       "      <td>0.684516</td>\n",
       "      <td>-7.891452</td>\n",
       "      <td>-5.400077</td>\n",
       "      <td>-0.686483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.508308</td>\n",
       "      <td>7.770800</td>\n",
       "      <td>0.805252</td>\n",
       "      <td>-7.918513</td>\n",
       "      <td>-2.891689</td>\n",
       "      <td>-0.767768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.570246</td>\n",
       "      <td>8.389577</td>\n",
       "      <td>0.393562</td>\n",
       "      <td>-7.962220</td>\n",
       "      <td>-6.837817</td>\n",
       "      <td>-0.395929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.445107</td>\n",
       "      <td>7.095747</td>\n",
       "      <td>1.609223</td>\n",
       "      <td>-8.017404</td>\n",
       "      <td>-6.068960</td>\n",
       "      <td>-1.387074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.168689</td>\n",
       "      <td>6.497754</td>\n",
       "      <td>0.670552</td>\n",
       "      <td>-8.148397</td>\n",
       "      <td>-6.321860</td>\n",
       "      <td>-0.794610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>5.680267</td>\n",
       "      <td>11.284864</td>\n",
       "      <td>5.544827</td>\n",
       "      <td>-8.292772</td>\n",
       "      <td>7.387823</td>\n",
       "      <td>-0.554777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1.758683</td>\n",
       "      <td>6.918942</td>\n",
       "      <td>1.006552</td>\n",
       "      <td>-8.762462</td>\n",
       "      <td>-5.596878</td>\n",
       "      <td>-1.329353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1.173941</td>\n",
       "      <td>9.143277</td>\n",
       "      <td>1.113148</td>\n",
       "      <td>-8.834819</td>\n",
       "      <td>-5.739133</td>\n",
       "      <td>-0.701423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.466887</td>\n",
       "      <td>7.333955</td>\n",
       "      <td>1.189662</td>\n",
       "      <td>-8.861746</td>\n",
       "      <td>-6.110520</td>\n",
       "      <td>-1.076219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>3.372556</td>\n",
       "      <td>12.498980</td>\n",
       "      <td>0.512236</td>\n",
       "      <td>-8.917743</td>\n",
       "      <td>-5.354666</td>\n",
       "      <td>-1.552550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>2.141475</td>\n",
       "      <td>11.987760</td>\n",
       "      <td>0.860192</td>\n",
       "      <td>-9.270064</td>\n",
       "      <td>-3.512306</td>\n",
       "      <td>-0.295800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1.032610</td>\n",
       "      <td>9.239806</td>\n",
       "      <td>2.014633</td>\n",
       "      <td>-9.609936</td>\n",
       "      <td>-7.707895</td>\n",
       "      <td>-0.839740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2.301503</td>\n",
       "      <td>10.895635</td>\n",
       "      <td>3.309486</td>\n",
       "      <td>-10.215888</td>\n",
       "      <td>-6.454583</td>\n",
       "      <td>-1.361502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.751536</td>\n",
       "      <td>19.005575</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>-10.446361</td>\n",
       "      <td>-11.442149</td>\n",
       "      <td>-1.145605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>3.382413</td>\n",
       "      <td>8.326282</td>\n",
       "      <td>1.108120</td>\n",
       "      <td>-10.490625</td>\n",
       "      <td>-7.454794</td>\n",
       "      <td>-1.209259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>4.957862</td>\n",
       "      <td>13.111002</td>\n",
       "      <td>3.015647</td>\n",
       "      <td>-10.515509</td>\n",
       "      <td>-7.227577</td>\n",
       "      <td>-1.695443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.802040</td>\n",
       "      <td>10.651378</td>\n",
       "      <td>1.809001</td>\n",
       "      <td>-10.605262</td>\n",
       "      <td>-4.560109</td>\n",
       "      <td>-1.108996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2.550878</td>\n",
       "      <td>9.406931</td>\n",
       "      <td>1.177149</td>\n",
       "      <td>-11.321408</td>\n",
       "      <td>-8.525999</td>\n",
       "      <td>-0.219363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>2.594556</td>\n",
       "      <td>10.129349</td>\n",
       "      <td>1.605846</td>\n",
       "      <td>-11.510535</td>\n",
       "      <td>-8.751062</td>\n",
       "      <td>-1.221262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1.232543</td>\n",
       "      <td>10.190377</td>\n",
       "      <td>2.214527</td>\n",
       "      <td>-11.646038</td>\n",
       "      <td>-8.662508</td>\n",
       "      <td>-1.167602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.083235</td>\n",
       "      <td>11.382222</td>\n",
       "      <td>1.863795</td>\n",
       "      <td>-11.944670</td>\n",
       "      <td>-5.423362</td>\n",
       "      <td>-0.872853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>3.271736</td>\n",
       "      <td>10.498418</td>\n",
       "      <td>2.568976</td>\n",
       "      <td>-12.190151</td>\n",
       "      <td>-7.654444</td>\n",
       "      <td>-1.058637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>2.103388</td>\n",
       "      <td>11.006883</td>\n",
       "      <td>1.982903</td>\n",
       "      <td>-12.553447</td>\n",
       "      <td>-9.498979</td>\n",
       "      <td>-1.182187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>19.309835</td>\n",
       "      <td>34.972227</td>\n",
       "      <td>8.782942</td>\n",
       "      <td>-12.734218</td>\n",
       "      <td>21.065910</td>\n",
       "      <td>-4.037891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3.691629</td>\n",
       "      <td>14.018850</td>\n",
       "      <td>2.271700</td>\n",
       "      <td>-15.790091</td>\n",
       "      <td>-10.479162</td>\n",
       "      <td>-1.668153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1860 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Health Science  Eco/Management/Information Science  \\\n",
       "1099        6.792594                           51.425815   \n",
       "1097        6.026349                           45.237231   \n",
       "1095        6.269215                           46.062585   \n",
       "1094        4.567594                           38.839720   \n",
       "1096        4.187867                           35.797508   \n",
       "1072       -0.079085                           14.739764   \n",
       "1074       -0.045572                           14.554470   \n",
       "1075       -0.009541                           14.244184   \n",
       "1092        3.682327                           30.873406   \n",
       "379         1.769244                            0.715017   \n",
       "1086       -0.269466                           12.385016   \n",
       "378         2.929369                            0.398331   \n",
       "1098        7.463085                           42.621399   \n",
       "1091        2.338080                           24.149025   \n",
       "1093        2.647496                           25.930554   \n",
       "1076       -0.731987                            9.141379   \n",
       "1081       -0.890561                            8.629187   \n",
       "1090        2.018854                           22.334911   \n",
       "377         0.937506                            3.296507   \n",
       "1079       -0.354659                            8.288146   \n",
       "1088        0.554317                           13.571790   \n",
       "1077       -0.144167                           12.007029   \n",
       "376        -0.304356                            0.838410   \n",
       "878        80.520674                          -11.436554   \n",
       "116         0.247338                           -0.366417   \n",
       "1078       -0.517564                            9.951490   \n",
       "1089        0.886581                           16.428028   \n",
       "455        -1.123603                           -0.433629   \n",
       "118        -0.587886                            0.077591   \n",
       "458        -0.477775                           -0.024315   \n",
       "...              ...                                 ...   \n",
       "217         0.081706                            5.950836   \n",
       "73          1.146572                            7.926956   \n",
       "92          0.635166                            8.495481   \n",
       "57          6.006436                           13.387637   \n",
       "1818        3.073442                           14.558544   \n",
       "91          0.315038                            6.246646   \n",
       "72          1.508308                            7.770800   \n",
       "90          1.570246                            8.389577   \n",
       "97          2.445107                            7.095747   \n",
       "95          0.168689                            6.497754   \n",
       "338         5.680267                           11.284864   \n",
       "1298        1.758683                            6.918942   \n",
       "1294        1.173941                            9.143277   \n",
       "94          0.466887                            7.333955   \n",
       "618         3.372556                           12.498980   \n",
       "1813        2.141475                           11.987760   \n",
       "1292        1.032610                            9.239806   \n",
       "615         2.301503                           10.895635   \n",
       "99          4.751536                           19.005575   \n",
       "1293        3.382413                            8.326282   \n",
       "619         4.957862                           13.111002   \n",
       "79          1.802040                           10.651378   \n",
       "93          2.550878                            9.406931   \n",
       "1296        2.594556                           10.129349   \n",
       "1299        1.232543                           10.190377   \n",
       "74          2.083235                           11.382222   \n",
       "1297        3.271736                           10.498418   \n",
       "1295        2.103388                           11.006883   \n",
       "59         19.309835                           34.972227   \n",
       "98          3.691629                           14.018850   \n",
       "\n",
       "      Linguistics/Anthropology  Economics/Liguistics  \\\n",
       "1099                -12.012572             24.189839   \n",
       "1097                -10.310231             20.063921   \n",
       "1095                -10.571448             19.775576   \n",
       "1094                 -9.881694             19.355789   \n",
       "1096                 -8.388246             14.623285   \n",
       "1072                 -6.380511             14.055628   \n",
       "1074                 -5.887818             12.158389   \n",
       "1075                 -5.789508             11.814996   \n",
       "1092                 -6.907567             11.219965   \n",
       "379                  33.938674             10.930074   \n",
       "1086                 -5.263747             10.904938   \n",
       "378                  31.385330             10.214708   \n",
       "1098                 -6.858952             10.144553   \n",
       "1091                 -5.697809              9.999609   \n",
       "1093                 -5.961211              9.919377   \n",
       "1076                 -4.674560              9.869595   \n",
       "1081                 -4.424517              9.190828   \n",
       "1090                 -5.469904              9.119674   \n",
       "377                  35.282706              8.974560   \n",
       "1079                 -4.238821              8.636402   \n",
       "1088                 -4.475542              8.443829   \n",
       "1077                 -4.409145              8.213212   \n",
       "376                  25.221924              7.908017   \n",
       "878                  -4.394274              7.792632   \n",
       "116                  21.076897              7.488942   \n",
       "1078                 -4.079647              7.399443   \n",
       "1089                 -4.560550              7.377625   \n",
       "455                  19.532094              7.355999   \n",
       "118                  20.441591              7.265287   \n",
       "458                  20.416913              6.999538   \n",
       "...                        ...                   ...   \n",
       "217                   0.576357             -7.269881   \n",
       "73                    3.205989             -7.383675   \n",
       "92                    0.387915             -7.407908   \n",
       "57                    4.549925             -7.745218   \n",
       "1818                  2.233110             -7.756019   \n",
       "91                    0.684516             -7.891452   \n",
       "72                    0.805252             -7.918513   \n",
       "90                    0.393562             -7.962220   \n",
       "97                    1.609223             -8.017404   \n",
       "95                    0.670552             -8.148397   \n",
       "338                   5.544827             -8.292772   \n",
       "1298                  1.006552             -8.762462   \n",
       "1294                  1.113148             -8.834819   \n",
       "94                    1.189662             -8.861746   \n",
       "618                   0.512236             -8.917743   \n",
       "1813                  0.860192             -9.270064   \n",
       "1292                  2.014633             -9.609936   \n",
       "615                   3.309486            -10.215888   \n",
       "99                    0.069792            -10.446361   \n",
       "1293                  1.108120            -10.490625   \n",
       "619                   3.015647            -10.515509   \n",
       "79                    1.809001            -10.605262   \n",
       "93                    1.177149            -11.321408   \n",
       "1296                  1.605846            -11.510535   \n",
       "1299                  2.214527            -11.646038   \n",
       "74                    1.863795            -11.944670   \n",
       "1297                  2.568976            -12.190151   \n",
       "1295                  1.982903            -12.553447   \n",
       "59                    8.782942            -12.734218   \n",
       "98                    2.271700            -15.790091   \n",
       "\n",
       "      Cultural Studies/Education/Multidisciplinary Science  \\\n",
       "1099                                          -0.015907      \n",
       "1097                                           0.120346      \n",
       "1095                                          -2.849042      \n",
       "1094                                          -3.100812      \n",
       "1096                                          -4.044344      \n",
       "1072                                          -0.573340      \n",
       "1074                                          -1.525371      \n",
       "1075                                          -1.671625      \n",
       "1092                                          -3.730409      \n",
       "379                                           -1.896182      \n",
       "1086                                          -0.836614      \n",
       "378                                           -2.868285      \n",
       "1098                                           0.374978      \n",
       "1091                                          -1.981896      \n",
       "1093                                          -1.513540      \n",
       "1076                                          -0.304183      \n",
       "1081                                          -0.225897      \n",
       "1090                                          -2.016384      \n",
       "377                                           -3.859279      \n",
       "1079                                           0.003778      \n",
       "1088                                           0.374883      \n",
       "1077                                          -1.199448      \n",
       "376                                           -1.319624      \n",
       "878                                           -3.422720      \n",
       "116                                           -2.837404      \n",
       "1078                                          -1.744707      \n",
       "1089                                          -2.010001      \n",
       "455                                           -3.582294      \n",
       "118                                           -4.254151      \n",
       "458                                           -1.959922      \n",
       "...                                                 ...      \n",
       "217                                           -5.590955      \n",
       "73                                            -2.546485      \n",
       "92                                            -6.069405      \n",
       "57                                             6.676387      \n",
       "1818                                          -0.070212      \n",
       "91                                            -5.400077      \n",
       "72                                            -2.891689      \n",
       "90                                            -6.837817      \n",
       "97                                            -6.068960      \n",
       "95                                            -6.321860      \n",
       "338                                            7.387823      \n",
       "1298                                          -5.596878      \n",
       "1294                                          -5.739133      \n",
       "94                                            -6.110520      \n",
       "618                                           -5.354666      \n",
       "1813                                          -3.512306      \n",
       "1292                                          -7.707895      \n",
       "615                                           -6.454583      \n",
       "99                                           -11.442149      \n",
       "1293                                          -7.454794      \n",
       "619                                           -7.227577      \n",
       "79                                            -4.560109      \n",
       "93                                            -8.525999      \n",
       "1296                                          -8.751062      \n",
       "1299                                          -8.662508      \n",
       "74                                            -5.423362      \n",
       "1297                                          -7.654444      \n",
       "1295                                          -9.498979      \n",
       "59                                            21.065910      \n",
       "98                                           -10.479162      \n",
       "\n",
       "      Neural/Behavioral Science  \n",
       "1099                   1.443752  \n",
       "1097                   1.136332  \n",
       "1095                   1.304156  \n",
       "1094                   1.945805  \n",
       "1096                   1.670367  \n",
       "1072                   1.501939  \n",
       "1074                   1.168936  \n",
       "1075                   1.200214  \n",
       "1092                   1.459632  \n",
       "379                    0.590886  \n",
       "1086                   0.966956  \n",
       "378                   -0.816149  \n",
       "1098                   1.128835  \n",
       "1091                   0.913696  \n",
       "1093                   0.470958  \n",
       "1076                   0.789829  \n",
       "1081                   0.678249  \n",
       "1090                   0.572259  \n",
       "377                    2.369375  \n",
       "1079                   1.975965  \n",
       "1088                   0.340689  \n",
       "1077                   0.484501  \n",
       "376                   -0.249330  \n",
       "878                   -6.224189  \n",
       "116                    0.351668  \n",
       "1078                   0.636453  \n",
       "1089                   0.570564  \n",
       "455                   -0.253144  \n",
       "118                   -0.660191  \n",
       "458                    0.455390  \n",
       "...                         ...  \n",
       "217                   -0.648175  \n",
       "73                    -0.263868  \n",
       "92                    -0.576852  \n",
       "57                    -1.958899  \n",
       "1818                  -0.623864  \n",
       "91                    -0.686483  \n",
       "72                    -0.767768  \n",
       "90                    -0.395929  \n",
       "97                    -1.387074  \n",
       "95                    -0.794610  \n",
       "338                   -0.554777  \n",
       "1298                  -1.329353  \n",
       "1294                  -0.701423  \n",
       "94                    -1.076219  \n",
       "618                   -1.552550  \n",
       "1813                  -0.295800  \n",
       "1292                  -0.839740  \n",
       "615                   -1.361502  \n",
       "99                    -1.145605  \n",
       "1293                  -1.209259  \n",
       "619                   -1.695443  \n",
       "79                    -1.108996  \n",
       "93                    -0.219363  \n",
       "1296                  -1.221262  \n",
       "1299                  -1.167602  \n",
       "74                    -0.872853  \n",
       "1297                  -1.058637  \n",
       "1295                  -1.182187  \n",
       "59                    -4.037891  \n",
       "98                    -1.668153  \n",
       "\n",
       "[1860 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by='Economics/Liguistics',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECONOMICS                                           46.416667\n",
       "MANAGEMENT                                          14.000000\n",
       "INFORMATION SCIENCE & LIBRARY SCIENCE               12.500000\n",
       "LAW                                                  9.500000\n",
       "PUBLIC ADMINISTRATION                                7.500000\n",
       "COMPUTER SCIENCE, INFORMATION SYSTEMS                6.083333\n",
       "OPERATIONS RESEARCH & MANAGEMENT SCIENCE             3.833333\n",
       "PLANNING & DEVELOPMENT                               3.666667\n",
       "GEOGRAPHY                                            3.500000\n",
       "TELECOMMUNICATIONS                                   3.333333\n",
       "STATISTICS & PROBABILITY                             2.666667\n",
       "SOCIAL SCIENCES, MATHEMATICAL METHODS                2.500000\n",
       "ENVIRONMENTAL STUDIES                                2.416667\n",
       "ENGINEERING, ELECTRICAL & ELECTRONIC                 1.833333\n",
       "COMPUTER SCIENCE, SOFTWARE ENGINEERING               1.833333\n",
       "ENVIRONMENTAL SCIENCES                               1.583333\n",
       "BUSINESS, FINANCE                                    1.500000\n",
       "COMPUTER SCIENCE, THEORY & METHODS                   1.083333\n",
       "MULTIDISCIPLINARY SCIENCES                           1.000000\n",
       "INDUSTRIAL RELATIONS & LABOR                         1.000000\n",
       "INTERNATIONAL RELATIONS                              1.000000\n",
       "COMPUTER SCIENCE, INTERDISCIPLINARY APPLICATIONS     0.833333\n",
       "COMPUTER SCIENCE, HARDWARE & ARCHITECTURE            0.833333\n",
       "URBAN STUDIES                                        0.833333\n",
       "MATHEMATICS, INTERDISCIPLINARY APPLICATIONS          0.833333\n",
       "AREA STUDIES                                         0.833333\n",
       "ENGINEERING, INDUSTRIAL                              0.666667\n",
       "COMPUTER SCIENCE, ARTIFICIAL INTELLIGENCE            0.666667\n",
       "ERGONOMICS                                           0.500000\n",
       "ETHNIC STUDIES                                       0.500000\n",
       "                                                      ...    \n",
       "INTEGRATIVE & COMPLEMENTARY MEDICINE                 0.000000\n",
       "EDUCATION, SPECIAL                                   0.000000\n",
       "PERIPHERAL VASCULAR DISEASE                          0.000000\n",
       "EMERGENCY MEDICINE                                   0.000000\n",
       "OPHTHALMOLOGY                                        0.000000\n",
       "AUDIOLOGY & SPEECH-LANGUAGE PATHOLOGY                0.000000\n",
       "ENGINEERING, MANUFACTURING                           0.000000\n",
       "AUTOMATION & CONTROL SYSTEMS                         0.000000\n",
       "TRANSPORTATION SCIENCE & TECHNOLOGY                  0.000000\n",
       "ROBOTICS                                             0.000000\n",
       "AGRICULTURAL ECONOMICS & POLICY                      0.000000\n",
       "REPRODUCTIVE BIOLOGY                                 0.000000\n",
       "AGRICULTURE, MULTIDISCIPLINARY                       0.000000\n",
       "CHEMISTRY, APPLIED                                   0.000000\n",
       "ORTHOPEDICS                                          0.000000\n",
       "TOXICOLOGY                                           0.000000\n",
       "DERMATOLOGY                                          0.000000\n",
       "RHEUMATOLOGY                                         0.000000\n",
       "ENGINEERING, ENVIRONMENTAL                           0.000000\n",
       "DEVELOPMENTAL BIOLOGY                                0.000000\n",
       "INSTRUMENTS & INSTRUMENTATION                        0.000000\n",
       "OPTICS                                               0.000000\n",
       "DENTISTRY, ORAL SURGERY & MEDICINE                   0.000000\n",
       "MATERIALS SCIENCE, PAPER & WOOD                      0.000000\n",
       "FORESTRY                                             0.000000\n",
       "GEOGRAPHY, PHYSICAL                                  0.000000\n",
       "ACOUSTICS                                            0.000000\n",
       "OTORHINOLARYNGOLOGY                                  0.000000\n",
       "UROLOGY & NEPHROLOGY                                 0.000000\n",
       "LINGUISTICS                                          0.000000\n",
       "Name: 1097, Length: 196, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.iloc[1097].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1100-93*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'African Journalism Studies': 70,\n",
       " 'Argumentation': 1,\n",
       " 'Asian Journal of Communication': 73,\n",
       " 'Augmentative and Alternative Communication': 89,\n",
       " 'COMMUNICATION EDUCATION': 83,\n",
       " 'COMMUNICATION MONOGRAPHS': 2,\n",
       " 'COMMUNICATION RESEARCH': 33,\n",
       " 'COMMUNICATION THEORY': 37,\n",
       " 'CRITICAL STUDIES IN MASS COMMUNICATION': 81,\n",
       " 'CRITICAL STUDIES IN MEDIA COMMUNICATION': 46,\n",
       " 'CYBERPSYCHOLOGY & BEHAVIOR': 88,\n",
       " 'Chinese Journal of Communication': 57,\n",
       " 'Communication Culture & Critique': 62,\n",
       " 'Communication and Critical-Cultural Studies': 69,\n",
       " 'Communications-European Journal of Communication Research': 20,\n",
       " 'Comunicacion y Sociedad': 92,\n",
       " 'Comunicar': 27,\n",
       " 'Continuum-Journal of Media & Cultural Studies': 21,\n",
       " 'Convergence-The International Journal of Research into New Media Technologies': 50,\n",
       " 'Critical Discourse Studies': 8,\n",
       " 'DISCOURSE & SOCIETY': 64,\n",
       " 'DISCOURSE STUDIES': 6,\n",
       " 'Discourse & Communication': 10,\n",
       " 'Discourse Context & Media': 26,\n",
       " 'EUROPEAN JOURNAL OF COMMUNICATION': 14,\n",
       " 'EUROPEAN JOURNAL OF DISORDERS OF COMMUNICATION': 85,\n",
       " 'Ecquid Novi-African Journalism Studies': 90,\n",
       " 'Environmental Communication-A Journal of Nature and Culture': 68,\n",
       " 'Estudios Sobre el Mensaje Periodistico': 93,\n",
       " 'Games and Culture': 42,\n",
       " 'HARVARD INTERNATIONAL JOURNAL OF PRESS-POLITICS': 87,\n",
       " 'HEALTH COMMUNICATION': 15,\n",
       " 'HUMAN COMMUNICATION RESEARCH': 77,\n",
       " 'IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION': 4,\n",
       " 'INTERNATIONAL JOURNAL OF CONFLICT MANAGEMENT': 5,\n",
       " 'INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS': 86,\n",
       " 'INTERNATIONAL JOURNAL OF PUBLIC OPINION RESEARCH': 53,\n",
       " 'Information Communication & Society': 3,\n",
       " 'Interaction Studies': 59,\n",
       " 'International Communication Gazette': 35,\n",
       " 'International Journal of Advertising': 43,\n",
       " 'International Journal of Communication': 12,\n",
       " 'International Journal of Mobile Communications': 91,\n",
       " 'International Journal of Press-Politics': 16,\n",
       " 'JAVNOST-THE PUBLIC': 67,\n",
       " 'JOURNAL OF ADVERTISING': 38,\n",
       " 'JOURNAL OF ADVERTISING RESEARCH': 72,\n",
       " 'JOURNAL OF APPLIED COMMUNICATION RESEARCH': 41,\n",
       " 'JOURNAL OF BROADCASTING & ELECTRONIC MEDIA': 13,\n",
       " 'JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION': 74,\n",
       " 'JOURNAL OF COMMUNICATION': 52,\n",
       " 'JOURNAL OF HEALTH COMMUNICATION': 44,\n",
       " 'JOURNAL OF LANGUAGE AND SOCIAL PSYCHOLOGY': 32,\n",
       " 'JOURNAL OF MEDIA ECONOMICS': 54,\n",
       " 'JOURNAL OF SOCIAL AND PERSONAL RELATIONSHIPS': 28,\n",
       " 'JOURNALISM & MASS COMMUNICATION QUARTERLY': 24,\n",
       " 'Journal of African Media Studies': 78,\n",
       " 'Journal of Computer-Mediated Communication': 34,\n",
       " 'Journal of Mass Media Ethics': 71,\n",
       " 'Journal of Media Psychology-Theories Methods and Applications': 25,\n",
       " 'Journal of Public Relations Research': 11,\n",
       " 'Journalism': 45,\n",
       " 'Journalism Studies': 61,\n",
       " 'LANGUAGE & COMMUNICATION': 19,\n",
       " 'LEARNED PUBLISHING': 82,\n",
       " 'MEDIA CULTURE & SOCIETY': 76,\n",
       " 'MEDIA PSYCHOLOGY': 40,\n",
       " 'Management Communication Quarterly': 65,\n",
       " 'Mass Communication and Society': 36,\n",
       " 'Media International Australia': 63,\n",
       " 'NARRATIVE INQUIRY': 22,\n",
       " 'NEW MEDIA & SOCIETY': 17,\n",
       " 'PERSONAL RELATIONSHIPS': 56,\n",
       " 'POLITICAL COMMUNICATION': 47,\n",
       " 'PUBLIC CULTURE': 80,\n",
       " 'PUBLIC OPINION QUARTERLY': 49,\n",
       " 'PUBLIC RELATIONS REVIEW': 31,\n",
       " 'PUBLIC UNDERSTANDING OF SCIENCE': 51,\n",
       " 'PUBLISHING RESEARCH QUARTERLY': 84,\n",
       " 'QUARTERLY JOURNAL OF SPEECH': 39,\n",
       " 'RESEARCH ON LANGUAGE AND SOCIAL INTERACTION': 66,\n",
       " 'Rhetoric Society Quarterly': 48,\n",
       " 'SCIENCE COMMUNICATION': 9,\n",
       " 'Social Semiotics': 58,\n",
       " 'TECHNICAL COMMUNICATION': 18,\n",
       " 'TELECOMMUNICATIONS POLICY': 55,\n",
       " 'Television & New Media': 60,\n",
       " 'Text & Talk': 23,\n",
       " 'Tijdschrift voor Communicatiewetenschap': 30,\n",
       " 'Translator': 29,\n",
       " 'Visual Communication': 7,\n",
       " 'WESTERN JOURNAL OF COMMUNICATION': 79,\n",
       " 'WRITTEN COMMUNICATION': 75}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.815291  , -1.17731752,  8.04157629,  3.69204127, -2.21082401,\n",
       "        -0.21062219]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 1 :\n",
      "PUBLIC, ENVIRONMENTAL & OCCUPATIONAL HEALTH\n",
      "MEDICINE, GENERAL & INTERNAL\n",
      "PSYCHIATRY\n",
      "ONCOLOGY\n",
      "NURSING\n",
      "-----------------------------\n",
      "Component 2 :\n",
      "ECONOMICS\n",
      "MANAGEMENT\n",
      "INFORMATION SCIENCE & LIBRARY SCIENCE\n",
      "COMPUTER SCIENCE, INFORMATION SYSTEMS\n",
      "SOCIAL SCIENCES, INTERDISCIPLINARY\n",
      "-----------------------------\n",
      "Component 3 :\n",
      "LINGUISTICS\n",
      "ANTHROPOLOGY\n",
      "EDUCATION & EDUCATIONAL RESEARCH\n",
      "MANAGEMENT\n",
      "SOCIAL SCIENCES, INTERDISCIPLINARY\n",
      "-----------------------------\n",
      "Component 4 :\n",
      "ECONOMICS\n",
      "LINGUISTICS\n",
      "PUBLIC, ENVIRONMENTAL & OCCUPATIONAL HEALTH\n",
      "ONCOLOGY\n",
      "NURSING\n",
      "-----------------------------\n",
      "Component 5 :\n",
      "CULTURAL STUDIES\n",
      "EDUCATION & EDUCATIONAL RESEARCH\n",
      "SOCIAL SCIENCES, INTERDISCIPLINARY\n",
      "INFORMATION SCIENCE & LIBRARY SCIENCE\n",
      "MULTIDISCIPLINARY SCIENCES\n",
      "-----------------------------\n",
      "Component 6 :\n",
      "PSYCHIATRY\n",
      "NEUROSCIENCES\n",
      "FAMILY STUDIES\n",
      "CLINICAL NEUROLOGY\n",
      "REHABILITATION\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "  print('Component',i+1,':')\n",
    "  print('\\n'.join(np.flip(np.array(externs)[np.argsort(pca.components_[i,:])[-5:]],0)))\n",
    "  print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_=pca.transform(X_pca)\n",
    "X_pca_=X_pca_.reshape((93,20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_[X2.sum(axis=2)==0,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=np.concatenate((X_pca_,COMM,PSY,BUSINESS,POL_SCI,SOCIOLOGY,co),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index=np.unique(np.random.randint(93,size=15))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_[sample_index]\n",
    "y_test=Y[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=np.delete(np.arange(93),sample_index)\n",
    "X_train=X_[train_index]\n",
    "y_train=Y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 12)\n",
      "(10, 20, 1)\n",
      "(83, 20, 12)\n",
      "(83, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurate_rate(y_true, y_pred):\n",
    "  diff=tf.to_float(K.abs(y_pred-y_true))/tf.to_float(y_true)\n",
    "  correct=K.less(diff,0.3)\n",
    "  return K.mean(correct)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  abs_diff=K.abs(y_pred-y_true)\n",
    "  correct=K.less(abs_diff,0.3)\n",
    "  return K.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleweights=np.zeros((93,20))\n",
    "sampleweights[X2.sum(axis=2)==0]=0\n",
    "sampleweights[X2.sum(axis=2)!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model(n_a,n_values):\n",
    "  model=Sequential()\n",
    "  model.add(Masking(mask_value=0., input_shape=(20,n_values)))\n",
    "  #model.add(Embedding(input_dim=1000, output_dim=128, input_length=10))\n",
    "  #model.add(LSTM(n_a, activation='tanh',return_sequences=True,dropout=0.1))\n",
    "  model.add(SimpleRNN(n_a, activation='tanh',return_sequences=True))\n",
    "  #model.add(GRU(n_a, activation='tanh',return_sequences=True))\n",
    "  model.add(Dense(10))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dropout(0.1))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss='mean_squared_error',sample_weight_mode=\"temporal\", optimizer='sgd')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 1.3491\n",
      "Epoch 2/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 1.0140\n",
      "Epoch 3/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.8757\n",
      "Epoch 4/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.8399\n",
      "Epoch 5/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.8184\n",
      "Epoch 6/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.7862\n",
      "Epoch 7/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.8094\n",
      "Epoch 8/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.7731\n",
      "Epoch 9/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.7643\n",
      "Epoch 10/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.7506\n",
      "Epoch 11/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.7498\n",
      "Epoch 12/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.7391\n",
      "Epoch 13/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.7389\n",
      "Epoch 14/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.7395\n",
      "Epoch 15/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.7285\n",
      "Epoch 16/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.7452\n",
      "Epoch 17/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.7521\n",
      "Epoch 18/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.7100\n",
      "Epoch 19/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.6964\n",
      "Epoch 20/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6953\n",
      "Epoch 21/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.7015\n",
      "Epoch 22/1000\n",
      "93/93 [==============================] - 0s 474us/step - loss: 0.6886\n",
      "Epoch 23/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.7071\n",
      "Epoch 24/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6886\n",
      "Epoch 25/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.6875\n",
      "Epoch 26/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.6761\n",
      "Epoch 27/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6883\n",
      "Epoch 28/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.6646\n",
      "Epoch 29/1000\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.6681\n",
      "Epoch 30/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.6510\n",
      "Epoch 31/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.6819\n",
      "Epoch 32/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.6632\n",
      "Epoch 33/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6694\n",
      "Epoch 34/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6424\n",
      "Epoch 35/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6780\n",
      "Epoch 36/1000\n",
      "93/93 [==============================] - 0s 268us/step - loss: 0.6601\n",
      "Epoch 37/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6505\n",
      "Epoch 38/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6543\n",
      "Epoch 39/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.6749\n",
      "Epoch 40/1000\n",
      "93/93 [==============================] - 0s 260us/step - loss: 0.6626\n",
      "Epoch 41/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.6546\n",
      "Epoch 42/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6566\n",
      "Epoch 43/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.6446\n",
      "Epoch 44/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.6458\n",
      "Epoch 45/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6585\n",
      "Epoch 46/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6544\n",
      "Epoch 47/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6547\n",
      "Epoch 48/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6304\n",
      "Epoch 49/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6430\n",
      "Epoch 50/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6525\n",
      "Epoch 51/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.6458\n",
      "Epoch 52/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.6382\n",
      "Epoch 53/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6329\n",
      "Epoch 54/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6488\n",
      "Epoch 55/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6531\n",
      "Epoch 56/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.6520\n",
      "Epoch 57/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.6324\n",
      "Epoch 58/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6429\n",
      "Epoch 59/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6282\n",
      "Epoch 60/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.6335\n",
      "Epoch 61/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6048\n",
      "Epoch 62/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.6488\n",
      "Epoch 63/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6360\n",
      "Epoch 64/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6266\n",
      "Epoch 65/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.6220\n",
      "Epoch 66/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5880\n",
      "Epoch 67/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.6311\n",
      "Epoch 68/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.6308\n",
      "Epoch 69/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.6314\n",
      "Epoch 70/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6127\n",
      "Epoch 71/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.6099\n",
      "Epoch 72/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.6165\n",
      "Epoch 73/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6087\n",
      "Epoch 74/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.6156\n",
      "Epoch 75/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.5999\n",
      "Epoch 76/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5969\n",
      "Epoch 77/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6219\n",
      "Epoch 78/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6023\n",
      "Epoch 79/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.6067\n",
      "Epoch 80/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6062\n",
      "Epoch 81/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5955\n",
      "Epoch 82/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5922\n",
      "Epoch 83/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6085\n",
      "Epoch 84/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6018\n",
      "Epoch 85/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5820\n",
      "Epoch 86/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.6034\n",
      "Epoch 87/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5906\n",
      "Epoch 88/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5909\n",
      "Epoch 89/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5957\n",
      "Epoch 90/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5939\n",
      "Epoch 91/1000\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.5868\n",
      "Epoch 92/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.6046\n",
      "Epoch 93/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.6113\n",
      "Epoch 94/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5824\n",
      "Epoch 95/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5744\n",
      "Epoch 96/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5646\n",
      "Epoch 97/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5722\n",
      "Epoch 98/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.5666\n",
      "Epoch 99/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.5892\n",
      "Epoch 100/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5801\n",
      "Epoch 101/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5714\n",
      "Epoch 102/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.5663\n",
      "Epoch 103/1000\n",
      "93/93 [==============================] - 0s 236us/step - loss: 0.5902\n",
      "Epoch 104/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5623\n",
      "Epoch 105/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5854\n",
      "Epoch 106/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5665\n",
      "Epoch 107/1000\n",
      "93/93 [==============================] - 0s 281us/step - loss: 0.5764\n",
      "Epoch 108/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5868\n",
      "Epoch 109/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5631\n",
      "Epoch 110/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5767\n",
      "Epoch 111/1000\n",
      "93/93 [==============================] - 0s 260us/step - loss: 0.5658\n",
      "Epoch 112/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5606\n",
      "Epoch 113/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5611\n",
      "Epoch 114/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5723\n",
      "Epoch 115/1000\n",
      "93/93 [==============================] - 0s 242us/step - loss: 0.5476\n",
      "Epoch 116/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5603\n",
      "Epoch 117/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5612\n",
      "Epoch 118/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.5524\n",
      "Epoch 119/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5563\n",
      "Epoch 120/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5493\n",
      "Epoch 121/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5546\n",
      "Epoch 122/1000\n",
      "93/93 [==============================] - 0s 268us/step - loss: 0.5673\n",
      "Epoch 123/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5592\n",
      "Epoch 124/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5399\n",
      "Epoch 125/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5776\n",
      "Epoch 126/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5562\n",
      "Epoch 127/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5534\n",
      "Epoch 128/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5491\n",
      "Epoch 129/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5798\n",
      "Epoch 130/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5632\n",
      "Epoch 131/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5379\n",
      "Epoch 132/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5249\n",
      "Epoch 133/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5592\n",
      "Epoch 134/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5615\n",
      "Epoch 135/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5544\n",
      "Epoch 136/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5484\n",
      "Epoch 137/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5539\n",
      "Epoch 138/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5397\n",
      "Epoch 139/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.424 - 0s 237us/step - loss: 0.5401\n",
      "Epoch 140/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5547\n",
      "Epoch 141/1000\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.5552\n",
      "Epoch 142/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.5316\n",
      "Epoch 143/1000\n",
      "93/93 [==============================] - 0s 228us/step - loss: 0.5390\n",
      "Epoch 144/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5571\n",
      "Epoch 145/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5490\n",
      "Epoch 146/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5312\n",
      "Epoch 147/1000\n",
      "93/93 [==============================] - 0s 249us/step - loss: 0.5375\n",
      "Epoch 148/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5570\n",
      "Epoch 149/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5465\n",
      "Epoch 150/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5426\n",
      "Epoch 151/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5285\n",
      "Epoch 152/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5452\n",
      "Epoch 153/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5279\n",
      "Epoch 154/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5249\n",
      "Epoch 155/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.5300\n",
      "Epoch 156/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5411\n",
      "Epoch 157/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5312\n",
      "Epoch 158/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5322\n",
      "Epoch 159/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5090\n",
      "Epoch 160/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.5264\n",
      "Epoch 161/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.5377\n",
      "Epoch 162/1000\n",
      "93/93 [==============================] - 0s 324us/step - loss: 0.5450\n",
      "Epoch 163/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5225\n",
      "Epoch 164/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5386\n",
      "Epoch 165/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5157\n",
      "Epoch 166/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.5193\n",
      "Epoch 167/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5169\n",
      "Epoch 168/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5250\n",
      "Epoch 169/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5367\n",
      "Epoch 170/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5281\n",
      "Epoch 171/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5335\n",
      "Epoch 172/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5278\n",
      "Epoch 173/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5376\n",
      "Epoch 174/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5293\n",
      "Epoch 175/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.5227\n",
      "Epoch 176/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5324\n",
      "Epoch 177/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5335\n",
      "Epoch 178/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.5436\n",
      "Epoch 179/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5260\n",
      "Epoch 180/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5173\n",
      "Epoch 181/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5221\n",
      "Epoch 182/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5241\n",
      "Epoch 183/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5239\n",
      "Epoch 184/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4978\n",
      "Epoch 185/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5040\n",
      "Epoch 186/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5205\n",
      "Epoch 187/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5289\n",
      "Epoch 188/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5337\n",
      "Epoch 189/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5079\n",
      "Epoch 190/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5115\n",
      "Epoch 191/1000\n",
      "93/93 [==============================] - 0s 244us/step - loss: 0.5230\n",
      "Epoch 192/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5393\n",
      "Epoch 193/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5234\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 280us/step - loss: 0.5196\n",
      "Epoch 195/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.5170\n",
      "Epoch 196/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5205\n",
      "Epoch 197/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5054\n",
      "Epoch 198/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5171\n",
      "Epoch 199/1000\n",
      "93/93 [==============================] - 0s 351us/step - loss: 0.5231\n",
      "Epoch 200/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5290\n",
      "Epoch 201/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5366\n",
      "Epoch 202/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.5113\n",
      "Epoch 203/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5196\n",
      "Epoch 204/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5131\n",
      "Epoch 205/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5046\n",
      "Epoch 206/1000\n",
      "93/93 [==============================] - 0s 212us/step - loss: 0.5361\n",
      "Epoch 207/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5064\n",
      "Epoch 208/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5235\n",
      "Epoch 209/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5200\n",
      "Epoch 210/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5085\n",
      "Epoch 211/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5070\n",
      "Epoch 212/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5168\n",
      "Epoch 213/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.5219\n",
      "Epoch 214/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.5151\n",
      "Epoch 215/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5304\n",
      "Epoch 216/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5135\n",
      "Epoch 217/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5143\n",
      "Epoch 218/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.5135\n",
      "Epoch 219/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5049\n",
      "Epoch 220/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4999\n",
      "Epoch 221/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5180\n",
      "Epoch 222/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5010\n",
      "Epoch 223/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5313\n",
      "Epoch 224/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5083\n",
      "Epoch 225/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5199\n",
      "Epoch 226/1000\n",
      "93/93 [==============================] - 0s 228us/step - loss: 0.5168\n",
      "Epoch 227/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5086\n",
      "Epoch 228/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5065\n",
      "Epoch 229/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5146\n",
      "Epoch 230/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4902\n",
      "Epoch 231/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5019\n",
      "Epoch 232/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5197\n",
      "Epoch 233/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5028\n",
      "Epoch 234/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.5055\n",
      "Epoch 235/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4985\n",
      "Epoch 236/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4865\n",
      "Epoch 237/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4906\n",
      "Epoch 238/1000\n",
      "93/93 [==============================] - 0s 245us/step - loss: 0.4914\n",
      "Epoch 239/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5138\n",
      "Epoch 240/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5105\n",
      "Epoch 241/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5113\n",
      "Epoch 242/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4960\n",
      "Epoch 243/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.5070\n",
      "Epoch 244/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4964\n",
      "Epoch 245/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5001\n",
      "Epoch 246/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5003\n",
      "Epoch 247/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4965\n",
      "Epoch 248/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5090\n",
      "Epoch 249/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4987\n",
      "Epoch 250/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4861\n",
      "Epoch 251/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5105\n",
      "Epoch 252/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4890\n",
      "Epoch 253/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5003\n",
      "Epoch 254/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4887\n",
      "Epoch 255/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5116\n",
      "Epoch 256/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5071\n",
      "Epoch 257/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5073\n",
      "Epoch 258/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.5147\n",
      "Epoch 259/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4985\n",
      "Epoch 260/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4963\n",
      "Epoch 261/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5173\n",
      "Epoch 262/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5063\n",
      "Epoch 263/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5059\n",
      "Epoch 264/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4969\n",
      "Epoch 265/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4915\n",
      "Epoch 266/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4987\n",
      "Epoch 267/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5028\n",
      "Epoch 268/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5030\n",
      "Epoch 269/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5064\n",
      "Epoch 270/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4976\n",
      "Epoch 271/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4969\n",
      "Epoch 272/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5029\n",
      "Epoch 273/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5024\n",
      "Epoch 274/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5029\n",
      "Epoch 275/1000\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.5109\n",
      "Epoch 276/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4981\n",
      "Epoch 277/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5000\n",
      "Epoch 278/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4975\n",
      "Epoch 279/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4865\n",
      "Epoch 280/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.5226\n",
      "Epoch 281/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4907\n",
      "Epoch 282/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.5070\n",
      "Epoch 283/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4890\n",
      "Epoch 284/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5088\n",
      "Epoch 285/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4896\n",
      "Epoch 286/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4980\n",
      "Epoch 287/1000\n",
      "93/93 [==============================] - 0s 195us/step - loss: 0.4892\n",
      "Epoch 288/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4951\n",
      "Epoch 289/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4910\n",
      "Epoch 290/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4927\n",
      "Epoch 291/1000\n",
      "93/93 [==============================] - 0s 230us/step - loss: 0.5060\n",
      "Epoch 292/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5034\n",
      "Epoch 293/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4988\n",
      "Epoch 294/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4779\n",
      "Epoch 295/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4931\n",
      "Epoch 296/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4954\n",
      "Epoch 297/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5020\n",
      "Epoch 298/1000\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.4991\n",
      "Epoch 299/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4860\n",
      "Epoch 300/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4863\n",
      "Epoch 301/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.4869\n",
      "Epoch 302/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.5026\n",
      "Epoch 303/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.5043\n",
      "Epoch 304/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4800\n",
      "Epoch 305/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4804\n",
      "Epoch 306/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4884\n",
      "Epoch 307/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4840\n",
      "Epoch 308/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4767\n",
      "Epoch 309/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4836\n",
      "Epoch 310/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4912\n",
      "Epoch 311/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4902\n",
      "Epoch 312/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4985\n",
      "Epoch 313/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4834\n",
      "Epoch 314/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4895\n",
      "Epoch 315/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.5032\n",
      "Epoch 316/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4679\n",
      "Epoch 317/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4882\n",
      "Epoch 318/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4935\n",
      "Epoch 319/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4877\n",
      "Epoch 320/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4917\n",
      "Epoch 321/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4889\n",
      "Epoch 322/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4937\n",
      "Epoch 323/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4688\n",
      "Epoch 324/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4900\n",
      "Epoch 325/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4759\n",
      "Epoch 326/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4875\n",
      "Epoch 327/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4770\n",
      "Epoch 328/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4909\n",
      "Epoch 329/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4781\n",
      "Epoch 330/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4798\n",
      "Epoch 331/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4830\n",
      "Epoch 332/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4750\n",
      "Epoch 333/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4783\n",
      "Epoch 334/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4897\n",
      "Epoch 335/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.5016\n",
      "Epoch 336/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4966\n",
      "Epoch 337/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4669\n",
      "Epoch 338/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4771\n",
      "Epoch 339/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4645\n",
      "Epoch 340/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4812\n",
      "Epoch 341/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4856\n",
      "Epoch 342/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4625\n",
      "Epoch 343/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4845\n",
      "Epoch 344/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4954\n",
      "Epoch 345/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4754\n",
      "Epoch 346/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4554\n",
      "Epoch 347/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4867\n",
      "Epoch 348/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4772\n",
      "Epoch 349/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4813\n",
      "Epoch 350/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4881\n",
      "Epoch 351/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.4676\n",
      "Epoch 352/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4871\n",
      "Epoch 353/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4818\n",
      "Epoch 354/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4933\n",
      "Epoch 355/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4912\n",
      "Epoch 356/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4773\n",
      "Epoch 357/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4886\n",
      "Epoch 358/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4772\n",
      "Epoch 359/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4752\n",
      "Epoch 360/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4760\n",
      "Epoch 361/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4822\n",
      "Epoch 362/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4795\n",
      "Epoch 363/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4882\n",
      "Epoch 364/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4930\n",
      "Epoch 365/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4608\n",
      "Epoch 366/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4770\n",
      "Epoch 367/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4790\n",
      "Epoch 368/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4784\n",
      "Epoch 369/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4714\n",
      "Epoch 370/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4810\n",
      "Epoch 371/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4688\n",
      "Epoch 372/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4698\n",
      "Epoch 373/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4629\n",
      "Epoch 374/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4842\n",
      "Epoch 375/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4841\n",
      "Epoch 376/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4744\n",
      "Epoch 377/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4689\n",
      "Epoch 378/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4854\n",
      "Epoch 379/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4600\n",
      "Epoch 380/1000\n",
      "93/93 [==============================] - 0s 242us/step - loss: 0.4689\n",
      "Epoch 381/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4785\n",
      "Epoch 382/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4820\n",
      "Epoch 383/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4847\n",
      "Epoch 384/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4716\n",
      "Epoch 385/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4765\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 237us/step - loss: 0.4790\n",
      "Epoch 387/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4696\n",
      "Epoch 388/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.4781\n",
      "Epoch 389/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4731\n",
      "Epoch 390/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4924\n",
      "Epoch 391/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4768\n",
      "Epoch 392/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.4700\n",
      "Epoch 393/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4733\n",
      "Epoch 394/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4838\n",
      "Epoch 395/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4608\n",
      "Epoch 396/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4750\n",
      "Epoch 397/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4894\n",
      "Epoch 398/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4764\n",
      "Epoch 399/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4719\n",
      "Epoch 400/1000\n",
      "93/93 [==============================] - 0s 241us/step - loss: 0.4722\n",
      "Epoch 401/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4678\n",
      "Epoch 402/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4530\n",
      "Epoch 403/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4728\n",
      "Epoch 404/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4702\n",
      "Epoch 405/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4817\n",
      "Epoch 406/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4611\n",
      "Epoch 407/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4597\n",
      "Epoch 408/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4751\n",
      "Epoch 409/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4662\n",
      "Epoch 410/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4665\n",
      "Epoch 411/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4573\n",
      "Epoch 412/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4751\n",
      "Epoch 413/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.5043\n",
      "Epoch 414/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4876\n",
      "Epoch 415/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4535\n",
      "Epoch 416/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4832\n",
      "Epoch 417/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4734\n",
      "Epoch 418/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4650\n",
      "Epoch 419/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4875\n",
      "Epoch 420/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4589\n",
      "Epoch 421/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4726\n",
      "Epoch 422/1000\n",
      "93/93 [==============================] - 0s 345us/step - loss: 0.4480\n",
      "Epoch 423/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.4749\n",
      "Epoch 424/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4900\n",
      "Epoch 425/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4718\n",
      "Epoch 426/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4609\n",
      "Epoch 427/1000\n",
      "93/93 [==============================] - 0s 206us/step - loss: 0.4670\n",
      "Epoch 428/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4753\n",
      "Epoch 429/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4654\n",
      "Epoch 430/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4765\n",
      "Epoch 431/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4650\n",
      "Epoch 432/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4651\n",
      "Epoch 433/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4547\n",
      "Epoch 434/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4528\n",
      "Epoch 435/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4633\n",
      "Epoch 436/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4651\n",
      "Epoch 437/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4686\n",
      "Epoch 438/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4870\n",
      "Epoch 439/1000\n",
      "93/93 [==============================] - 0s 240us/step - loss: 0.4604\n",
      "Epoch 440/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4596\n",
      "Epoch 441/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4553\n",
      "Epoch 442/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4782\n",
      "Epoch 443/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4839\n",
      "Epoch 444/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4696\n",
      "Epoch 445/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4643\n",
      "Epoch 446/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4657\n",
      "Epoch 447/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4729\n",
      "Epoch 448/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4617\n",
      "Epoch 449/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4625\n",
      "Epoch 450/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4702\n",
      "Epoch 451/1000\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.4645\n",
      "Epoch 452/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4648\n",
      "Epoch 453/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4722\n",
      "Epoch 454/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4629\n",
      "Epoch 455/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4603\n",
      "Epoch 456/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4694\n",
      "Epoch 457/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4588\n",
      "Epoch 458/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4593\n",
      "Epoch 459/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4712\n",
      "Epoch 460/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4745\n",
      "Epoch 461/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4562\n",
      "Epoch 462/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4664\n",
      "Epoch 463/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4595\n",
      "Epoch 464/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4456\n",
      "Epoch 465/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4499\n",
      "Epoch 466/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4756\n",
      "Epoch 467/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4670\n",
      "Epoch 468/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4551\n",
      "Epoch 469/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4652\n",
      "Epoch 470/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4548\n",
      "Epoch 471/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4650\n",
      "Epoch 472/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4642\n",
      "Epoch 473/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4502\n",
      "Epoch 474/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4582\n",
      "Epoch 475/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4578\n",
      "Epoch 476/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4576\n",
      "Epoch 477/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4630\n",
      "Epoch 478/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4516\n",
      "Epoch 479/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4570\n",
      "Epoch 480/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4684\n",
      "Epoch 481/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4620\n",
      "Epoch 482/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4608\n",
      "Epoch 483/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4598\n",
      "Epoch 484/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4680\n",
      "Epoch 485/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4530\n",
      "Epoch 486/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4624\n",
      "Epoch 487/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4666\n",
      "Epoch 488/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4638\n",
      "Epoch 489/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4591\n",
      "Epoch 490/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4410\n",
      "Epoch 491/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4580\n",
      "Epoch 492/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4641\n",
      "Epoch 493/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4585\n",
      "Epoch 494/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4597\n",
      "Epoch 495/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4692\n",
      "Epoch 496/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4630\n",
      "Epoch 497/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4520\n",
      "Epoch 498/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4430\n",
      "Epoch 499/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4484\n",
      "Epoch 500/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4618\n",
      "Epoch 501/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4535\n",
      "Epoch 502/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4497\n",
      "Epoch 503/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4595\n",
      "Epoch 504/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4619\n",
      "Epoch 505/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4663\n",
      "Epoch 506/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4661\n",
      "Epoch 507/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4387\n",
      "Epoch 508/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4550\n",
      "Epoch 509/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4485\n",
      "Epoch 510/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4468\n",
      "Epoch 511/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4588\n",
      "Epoch 512/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4547\n",
      "Epoch 513/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4563\n",
      "Epoch 514/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4520\n",
      "Epoch 515/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.4594\n",
      "Epoch 516/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4502\n",
      "Epoch 517/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4579\n",
      "Epoch 518/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4704\n",
      "Epoch 519/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4502\n",
      "Epoch 520/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4515\n",
      "Epoch 521/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4574\n",
      "Epoch 522/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4707\n",
      "Epoch 523/1000\n",
      "93/93 [==============================] - 0s 250us/step - loss: 0.4449\n",
      "Epoch 524/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4548\n",
      "Epoch 525/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4404\n",
      "Epoch 526/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4515\n",
      "Epoch 527/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4604\n",
      "Epoch 528/1000\n",
      "93/93 [==============================] - 0s 214us/step - loss: 0.4639\n",
      "Epoch 529/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4484\n",
      "Epoch 530/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4561\n",
      "Epoch 531/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4393\n",
      "Epoch 532/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4564\n",
      "Epoch 533/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4665\n",
      "Epoch 534/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4243\n",
      "Epoch 535/1000\n",
      "93/93 [==============================] - 0s 274us/step - loss: 0.4605\n",
      "Epoch 536/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4433\n",
      "Epoch 537/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4516\n",
      "Epoch 538/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4467\n",
      "Epoch 539/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4585\n",
      "Epoch 540/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4627\n",
      "Epoch 541/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4485\n",
      "Epoch 542/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4459\n",
      "Epoch 543/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4516\n",
      "Epoch 544/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4504\n",
      "Epoch 545/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4482\n",
      "Epoch 546/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.4485\n",
      "Epoch 547/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4523\n",
      "Epoch 548/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4529\n",
      "Epoch 549/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4624\n",
      "Epoch 550/1000\n",
      "93/93 [==============================] - 0s 256us/step - loss: 0.4430\n",
      "Epoch 551/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4541\n",
      "Epoch 552/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4564\n",
      "Epoch 553/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4508\n",
      "Epoch 554/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4395\n",
      "Epoch 555/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.4504\n",
      "Epoch 556/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4395\n",
      "Epoch 557/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4577\n",
      "Epoch 558/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4518\n",
      "Epoch 559/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4468\n",
      "Epoch 560/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4424\n",
      "Epoch 561/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4449\n",
      "Epoch 562/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4476\n",
      "Epoch 563/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4342\n",
      "Epoch 564/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4449\n",
      "Epoch 565/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4429\n",
      "Epoch 566/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4590\n",
      "Epoch 567/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4544\n",
      "Epoch 568/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4451\n",
      "Epoch 569/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4496\n",
      "Epoch 570/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4511\n",
      "Epoch 571/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4515\n",
      "Epoch 572/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4404\n",
      "Epoch 573/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4525\n",
      "Epoch 574/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4379\n",
      "Epoch 575/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4435\n",
      "Epoch 576/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4553\n",
      "Epoch 577/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4384\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 237us/step - loss: 0.4540\n",
      "Epoch 579/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4411\n",
      "Epoch 580/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4601\n",
      "Epoch 581/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.4453\n",
      "Epoch 582/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4421\n",
      "Epoch 583/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4409\n",
      "Epoch 584/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4516\n",
      "Epoch 585/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4564\n",
      "Epoch 586/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4390\n",
      "Epoch 587/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4362\n",
      "Epoch 588/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4497\n",
      "Epoch 589/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4614\n",
      "Epoch 590/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4325\n",
      "Epoch 591/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4371\n",
      "Epoch 592/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4281\n",
      "Epoch 593/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4560\n",
      "Epoch 594/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4395\n",
      "Epoch 595/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.4382\n",
      "Epoch 596/1000\n",
      "93/93 [==============================] - 0s 340us/step - loss: 0.4393\n",
      "Epoch 597/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4400\n",
      "Epoch 598/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4422\n",
      "Epoch 599/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4374\n",
      "Epoch 600/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4285\n",
      "Epoch 601/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4331\n",
      "Epoch 602/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4394\n",
      "Epoch 603/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4330\n",
      "Epoch 604/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4329\n",
      "Epoch 605/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4326\n",
      "Epoch 606/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4472\n",
      "Epoch 607/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4511\n",
      "Epoch 608/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4358\n",
      "Epoch 609/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4378\n",
      "Epoch 610/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4444\n",
      "Epoch 611/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4538\n",
      "Epoch 612/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4392\n",
      "Epoch 613/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4437\n",
      "Epoch 614/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4348\n",
      "Epoch 615/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4409\n",
      "Epoch 616/1000\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.4379\n",
      "Epoch 617/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4544\n",
      "Epoch 618/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4347\n",
      "Epoch 619/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4363\n",
      "Epoch 620/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4293\n",
      "Epoch 621/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4415\n",
      "Epoch 622/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4433\n",
      "Epoch 623/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4313\n",
      "Epoch 624/1000\n",
      "93/93 [==============================] - 0s 222us/step - loss: 0.4387\n",
      "Epoch 625/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4270\n",
      "Epoch 626/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4442\n",
      "Epoch 627/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4420\n",
      "Epoch 628/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4404\n",
      "Epoch 629/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4445\n",
      "Epoch 630/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4279\n",
      "Epoch 631/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4501\n",
      "Epoch 632/1000\n",
      "93/93 [==============================] - 0s 249us/step - loss: 0.4345\n",
      "Epoch 633/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4371\n",
      "Epoch 634/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4417\n",
      "Epoch 635/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4308\n",
      "Epoch 636/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4377\n",
      "Epoch 637/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4413\n",
      "Epoch 638/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4439\n",
      "Epoch 639/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.4294\n",
      "Epoch 640/1000\n",
      "93/93 [==============================] - 0s 256us/step - loss: 0.4347\n",
      "Epoch 641/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4374\n",
      "Epoch 642/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4460\n",
      "Epoch 643/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4460\n",
      "Epoch 644/1000\n",
      "93/93 [==============================] - 0s 235us/step - loss: 0.4457\n",
      "Epoch 645/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4413\n",
      "Epoch 646/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4432\n",
      "Epoch 647/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4294\n",
      "Epoch 648/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4350\n",
      "Epoch 649/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4330\n",
      "Epoch 650/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4208\n",
      "Epoch 651/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4283\n",
      "Epoch 652/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4246\n",
      "Epoch 653/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4308\n",
      "Epoch 654/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4316\n",
      "Epoch 655/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4458\n",
      "Epoch 656/1000\n",
      "93/93 [==============================] - 0s 194us/step - loss: 0.4326\n",
      "Epoch 657/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4349\n",
      "Epoch 658/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4179\n",
      "Epoch 659/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4379\n",
      "Epoch 660/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4412\n",
      "Epoch 661/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4294\n",
      "Epoch 662/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4423\n",
      "Epoch 663/1000\n",
      "93/93 [==============================] - 0s 238us/step - loss: 0.4377\n",
      "Epoch 664/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4310\n",
      "Epoch 665/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4229\n",
      "Epoch 666/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4184\n",
      "Epoch 667/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4336\n",
      "Epoch 668/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4252\n",
      "Epoch 669/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4258\n",
      "Epoch 670/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4319\n",
      "Epoch 671/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4424\n",
      "Epoch 672/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4181\n",
      "Epoch 673/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4322\n",
      "Epoch 674/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4302\n",
      "Epoch 675/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4472\n",
      "Epoch 676/1000\n",
      "93/93 [==============================] - 0s 263us/step - loss: 0.4303\n",
      "Epoch 677/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4280\n",
      "Epoch 678/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4341\n",
      "Epoch 679/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4337\n",
      "Epoch 680/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4385\n",
      "Epoch 681/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4250\n",
      "Epoch 682/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4303\n",
      "Epoch 683/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4275\n",
      "Epoch 684/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4323\n",
      "Epoch 685/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4294\n",
      "Epoch 686/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4184\n",
      "Epoch 687/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4341\n",
      "Epoch 688/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4257\n",
      "Epoch 689/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4208\n",
      "Epoch 690/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4459\n",
      "Epoch 691/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4253\n",
      "Epoch 692/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4388\n",
      "Epoch 693/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4249\n",
      "Epoch 694/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4458\n",
      "Epoch 695/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4308\n",
      "Epoch 696/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4346\n",
      "Epoch 697/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4274\n",
      "Epoch 698/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4249\n",
      "Epoch 699/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4280\n",
      "Epoch 700/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4315\n",
      "Epoch 701/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4360\n",
      "Epoch 702/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4295\n",
      "Epoch 703/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4417\n",
      "Epoch 704/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4278\n",
      "Epoch 705/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4473\n",
      "Epoch 706/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4208\n",
      "Epoch 707/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4274\n",
      "Epoch 708/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4261\n",
      "Epoch 709/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4305\n",
      "Epoch 710/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4214\n",
      "Epoch 711/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4299\n",
      "Epoch 712/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4369\n",
      "Epoch 713/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4342\n",
      "Epoch 714/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4383\n",
      "Epoch 715/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4163\n",
      "Epoch 716/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4315\n",
      "Epoch 717/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4419\n",
      "Epoch 718/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.4212\n",
      "Epoch 719/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4338\n",
      "Epoch 720/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4259\n",
      "Epoch 721/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4288\n",
      "Epoch 722/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4276\n",
      "Epoch 723/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4363\n",
      "Epoch 724/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4203\n",
      "Epoch 725/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4343\n",
      "Epoch 726/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4183\n",
      "Epoch 727/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4379\n",
      "Epoch 728/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4304\n",
      "Epoch 729/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4322\n",
      "Epoch 730/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4384\n",
      "Epoch 731/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4237\n",
      "Epoch 732/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4292\n",
      "Epoch 733/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4101\n",
      "Epoch 734/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4143\n",
      "Epoch 735/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4292\n",
      "Epoch 736/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4395\n",
      "Epoch 737/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4324\n",
      "Epoch 738/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4157\n",
      "Epoch 739/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4266\n",
      "Epoch 740/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4262\n",
      "Epoch 741/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4203\n",
      "Epoch 742/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4205\n",
      "Epoch 743/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4249\n",
      "Epoch 744/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4191\n",
      "Epoch 745/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4337\n",
      "Epoch 746/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4173\n",
      "Epoch 747/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4253\n",
      "Epoch 748/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4149\n",
      "Epoch 749/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4324\n",
      "Epoch 750/1000\n",
      "93/93 [==============================] - 0s 262us/step - loss: 0.4206\n",
      "Epoch 751/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4333\n",
      "Epoch 752/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4272\n",
      "Epoch 753/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4205\n",
      "Epoch 754/1000\n",
      "93/93 [==============================] - 0s 265us/step - loss: 0.4340\n",
      "Epoch 755/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4335\n",
      "Epoch 756/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4182\n",
      "Epoch 757/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4191\n",
      "Epoch 758/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4232\n",
      "Epoch 759/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4305\n",
      "Epoch 760/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4257\n",
      "Epoch 761/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4231\n",
      "Epoch 762/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4360\n",
      "Epoch 763/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4206\n",
      "Epoch 764/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4188\n",
      "Epoch 765/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4372\n",
      "Epoch 766/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4359\n",
      "Epoch 767/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4228\n",
      "Epoch 768/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4167\n",
      "Epoch 769/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4262\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 234us/step - loss: 0.4231\n",
      "Epoch 771/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4428\n",
      "Epoch 772/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.4164\n",
      "Epoch 773/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4226\n",
      "Epoch 774/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4238\n",
      "Epoch 775/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.324 - 0s 237us/step - loss: 0.4190\n",
      "Epoch 776/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4186\n",
      "Epoch 777/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4230\n",
      "Epoch 778/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4179\n",
      "Epoch 779/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4096\n",
      "Epoch 780/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4161\n",
      "Epoch 781/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4368\n",
      "Epoch 782/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4211\n",
      "Epoch 783/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4183\n",
      "Epoch 784/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4331\n",
      "Epoch 785/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.4120\n",
      "Epoch 786/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4208\n",
      "Epoch 787/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4318\n",
      "Epoch 788/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4209\n",
      "Epoch 789/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4269\n",
      "Epoch 790/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4208\n",
      "Epoch 791/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4249\n",
      "Epoch 792/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4222\n",
      "Epoch 793/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4105\n",
      "Epoch 794/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4204\n",
      "Epoch 795/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4284\n",
      "Epoch 796/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4260\n",
      "Epoch 797/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4212\n",
      "Epoch 798/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4234\n",
      "Epoch 799/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4210\n",
      "Epoch 800/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4186\n",
      "Epoch 801/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4229\n",
      "Epoch 802/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4250\n",
      "Epoch 803/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4155\n",
      "Epoch 804/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4132\n",
      "Epoch 805/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4193\n",
      "Epoch 806/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4209\n",
      "Epoch 807/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4370\n",
      "Epoch 808/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4111\n",
      "Epoch 809/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4087\n",
      "Epoch 810/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4228\n",
      "Epoch 811/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4274\n",
      "Epoch 812/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4229\n",
      "Epoch 813/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.4128\n",
      "Epoch 814/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4324\n",
      "Epoch 815/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4153\n",
      "Epoch 816/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4247\n",
      "Epoch 817/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4217\n",
      "Epoch 818/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4179\n",
      "Epoch 819/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4157\n",
      "Epoch 820/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4154\n",
      "Epoch 821/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4085\n",
      "Epoch 822/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4088\n",
      "Epoch 823/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.4202\n",
      "Epoch 824/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4225\n",
      "Epoch 825/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4142\n",
      "Epoch 826/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4291\n",
      "Epoch 827/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4152\n",
      "Epoch 828/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4165\n",
      "Epoch 829/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4211\n",
      "Epoch 830/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.329 - 0s 226us/step - loss: 0.4178\n",
      "Epoch 831/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4238\n",
      "Epoch 832/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4095\n",
      "Epoch 833/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4243\n",
      "Epoch 834/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4388\n",
      "Epoch 835/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4251\n",
      "Epoch 836/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4114\n",
      "Epoch 837/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4266\n",
      "Epoch 838/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4120\n",
      "Epoch 839/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4090\n",
      "Epoch 840/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4139\n",
      "Epoch 841/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4146\n",
      "Epoch 842/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4222\n",
      "Epoch 843/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4150\n",
      "Epoch 844/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4128\n",
      "Epoch 845/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4335\n",
      "Epoch 846/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4098\n",
      "Epoch 847/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4144\n",
      "Epoch 848/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.4119\n",
      "Epoch 849/1000\n",
      "93/93 [==============================] - 0s 377us/step - loss: 0.3986\n",
      "Epoch 850/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4018\n",
      "Epoch 851/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4261\n",
      "Epoch 852/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3997\n",
      "Epoch 853/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4176\n",
      "Epoch 854/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4190\n",
      "Epoch 855/1000\n",
      "93/93 [==============================] - 0s 251us/step - loss: 0.4340\n",
      "Epoch 856/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4012\n",
      "Epoch 857/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4169\n",
      "Epoch 858/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4170\n",
      "Epoch 859/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4129\n",
      "Epoch 860/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4178\n",
      "Epoch 861/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4063\n",
      "Epoch 862/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4188\n",
      "Epoch 863/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4192\n",
      "Epoch 864/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4157\n",
      "Epoch 865/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 866/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.327 - 0s 248us/step - loss: 0.4055\n",
      "Epoch 867/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4088\n",
      "Epoch 868/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4116\n",
      "Epoch 869/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4013\n",
      "Epoch 870/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4171\n",
      "Epoch 871/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.4213\n",
      "Epoch 872/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4194\n",
      "Epoch 873/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4204\n",
      "Epoch 874/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4146\n",
      "Epoch 875/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4134\n",
      "Epoch 876/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3939\n",
      "Epoch 877/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4213\n",
      "Epoch 878/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4133\n",
      "Epoch 879/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4112\n",
      "Epoch 880/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4079\n",
      "Epoch 881/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4177\n",
      "Epoch 882/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3974\n",
      "Epoch 883/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4066\n",
      "Epoch 884/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4099\n",
      "Epoch 885/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4118\n",
      "Epoch 886/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4262\n",
      "Epoch 887/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4123\n",
      "Epoch 888/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.4115\n",
      "Epoch 889/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4071\n",
      "Epoch 890/1000\n",
      "93/93 [==============================] - 0s 245us/step - loss: 0.4074\n",
      "Epoch 891/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4101\n",
      "Epoch 892/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4327\n",
      "Epoch 893/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4090\n",
      "Epoch 894/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4194\n",
      "Epoch 895/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4042\n",
      "Epoch 896/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4079\n",
      "Epoch 897/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.4078\n",
      "Epoch 898/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4009\n",
      "Epoch 899/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4115\n",
      "Epoch 900/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4091\n",
      "Epoch 901/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4036\n",
      "Epoch 902/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4153\n",
      "Epoch 903/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3972\n",
      "Epoch 904/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4026\n",
      "Epoch 905/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4076\n",
      "Epoch 906/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4091\n",
      "Epoch 907/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4190\n",
      "Epoch 908/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4129\n",
      "Epoch 909/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4055\n",
      "Epoch 910/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4070\n",
      "Epoch 911/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3973\n",
      "Epoch 912/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4067\n",
      "Epoch 913/1000\n",
      "93/93 [==============================] - 0s 240us/step - loss: 0.4173\n",
      "Epoch 914/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4118\n",
      "Epoch 915/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4097\n",
      "Epoch 916/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4077\n",
      "Epoch 917/1000\n",
      "93/93 [==============================] - 0s 252us/step - loss: 0.4058\n",
      "Epoch 918/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4067\n",
      "Epoch 919/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4005\n",
      "Epoch 920/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4031\n",
      "Epoch 921/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4101\n",
      "Epoch 922/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4070\n",
      "Epoch 923/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4022\n",
      "Epoch 924/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4079\n",
      "Epoch 925/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4104\n",
      "Epoch 926/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4271\n",
      "Epoch 927/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.4003\n",
      "Epoch 928/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4174\n",
      "Epoch 929/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.4119\n",
      "Epoch 930/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4189\n",
      "Epoch 931/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4046\n",
      "Epoch 932/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3953\n",
      "Epoch 933/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4103\n",
      "Epoch 934/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4075\n",
      "Epoch 935/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3983\n",
      "Epoch 936/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4026\n",
      "Epoch 937/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4203\n",
      "Epoch 938/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4045\n",
      "Epoch 939/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4094\n",
      "Epoch 940/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.4031\n",
      "Epoch 941/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4113\n",
      "Epoch 942/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3870\n",
      "Epoch 943/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4023\n",
      "Epoch 944/1000\n",
      "93/93 [==============================] - 0s 345us/step - loss: 0.4054\n",
      "Epoch 945/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3950\n",
      "Epoch 946/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4102\n",
      "Epoch 947/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3985\n",
      "Epoch 948/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4044\n",
      "Epoch 949/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3939\n",
      "Epoch 950/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3986\n",
      "Epoch 951/1000\n",
      "93/93 [==============================] - 0s 235us/step - loss: 0.4022\n",
      "Epoch 952/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3941\n",
      "Epoch 953/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4010\n",
      "Epoch 954/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4080\n",
      "Epoch 955/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4042\n",
      "Epoch 956/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4073\n",
      "Epoch 957/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4052\n",
      "Epoch 958/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3963\n",
      "Epoch 959/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3962\n",
      "Epoch 960/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4037\n",
      "Epoch 961/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3937\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 248us/step - loss: 0.3970\n",
      "Epoch 963/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3853\n",
      "Epoch 964/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.4055\n",
      "Epoch 965/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.4055\n",
      "Epoch 966/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4131\n",
      "Epoch 967/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4030\n",
      "Epoch 968/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3984\n",
      "Epoch 969/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4099\n",
      "Epoch 970/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3995\n",
      "Epoch 971/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3995\n",
      "Epoch 972/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3946\n",
      "Epoch 973/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3984\n",
      "Epoch 974/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4106\n",
      "Epoch 975/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4060\n",
      "Epoch 976/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3936\n",
      "Epoch 977/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4057\n",
      "Epoch 978/1000\n",
      "93/93 [==============================] - 0s 268us/step - loss: 0.4024\n",
      "Epoch 979/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3962\n",
      "Epoch 980/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4089\n",
      "Epoch 981/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4011\n",
      "Epoch 982/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.3906\n",
      "Epoch 983/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3940\n",
      "Epoch 984/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3951\n",
      "Epoch 985/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3949\n",
      "Epoch 986/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3932\n",
      "Epoch 987/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3967\n",
      "Epoch 988/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3954\n",
      "Epoch 989/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.4078\n",
      "Epoch 990/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3924\n",
      "Epoch 991/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3932\n",
      "Epoch 992/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4017\n",
      "Epoch 993/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3997\n",
      "Epoch 994/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3879\n",
      "Epoch 995/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4100\n",
      "Epoch 996/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3804\n",
      "Epoch 997/1000\n",
      "93/93 [==============================] - 0s 236us/step - loss: 0.3911\n",
      "Epoch 998/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4025\n",
      "Epoch 999/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3883\n",
      "Epoch 1000/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3904\n",
      "Epoch 1/1000\n",
      "93/93 [==============================] - 0s 233us/step - loss: 0.3906\n",
      "Epoch 2/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4042\n",
      "Epoch 3/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.4004\n",
      "Epoch 4/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4031\n",
      "Epoch 5/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.4015\n",
      "Epoch 6/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3978\n",
      "Epoch 7/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3896\n",
      "Epoch 8/1000\n",
      "93/93 [==============================] - 0s 281us/step - loss: 0.3925\n",
      "Epoch 9/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4058\n",
      "Epoch 10/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3978\n",
      "Epoch 11/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.312 - 0s 248us/step - loss: 0.3941\n",
      "Epoch 12/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4016\n",
      "Epoch 13/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3985\n",
      "Epoch 14/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3964\n",
      "Epoch 15/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3954\n",
      "Epoch 16/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3940\n",
      "Epoch 17/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4115\n",
      "Epoch 18/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3951\n",
      "Epoch 19/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3999\n",
      "Epoch 20/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.4070\n",
      "Epoch 21/1000\n",
      "93/93 [==============================] - 0s 258us/step - loss: 0.3963\n",
      "Epoch 22/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3913\n",
      "Epoch 23/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4054\n",
      "Epoch 24/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.4057\n",
      "Epoch 25/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3821\n",
      "Epoch 26/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4040\n",
      "Epoch 27/1000\n",
      "93/93 [==============================] - 0s 258us/step - loss: 0.3957\n",
      "Epoch 28/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4045\n",
      "Epoch 29/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3957\n",
      "Epoch 30/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3845\n",
      "Epoch 31/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3863\n",
      "Epoch 32/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3963\n",
      "Epoch 33/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3935\n",
      "Epoch 34/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3903\n",
      "Epoch 35/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3991\n",
      "Epoch 36/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3910\n",
      "Epoch 37/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4138\n",
      "Epoch 38/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3832\n",
      "Epoch 39/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.4076\n",
      "Epoch 40/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4015\n",
      "Epoch 41/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3960\n",
      "Epoch 42/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3939\n",
      "Epoch 43/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3896\n",
      "Epoch 44/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3874\n",
      "Epoch 45/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3936\n",
      "Epoch 46/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3890\n",
      "Epoch 47/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.3925\n",
      "Epoch 48/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3981\n",
      "Epoch 49/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3877\n",
      "Epoch 50/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3782\n",
      "Epoch 51/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3801\n",
      "Epoch 52/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3890\n",
      "Epoch 53/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3836\n",
      "Epoch 54/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3899\n",
      "Epoch 55/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3880\n",
      "Epoch 56/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3902\n",
      "Epoch 57/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3944\n",
      "Epoch 58/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.4004\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 264us/step - loss: 0.3917\n",
      "Epoch 60/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3913\n",
      "Epoch 61/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3845\n",
      "Epoch 62/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.4108\n",
      "Epoch 63/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3851\n",
      "Epoch 64/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3918\n",
      "Epoch 65/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3863\n",
      "Epoch 66/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3906\n",
      "Epoch 67/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3978\n",
      "Epoch 68/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3960\n",
      "Epoch 69/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3852\n",
      "Epoch 70/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3850\n",
      "Epoch 71/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3898\n",
      "Epoch 72/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3798\n",
      "Epoch 73/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3949\n",
      "Epoch 74/1000\n",
      "93/93 [==============================] - 0s 247us/step - loss: 0.3812\n",
      "Epoch 75/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3876\n",
      "Epoch 76/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3970\n",
      "Epoch 77/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3849\n",
      "Epoch 78/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3925\n",
      "Epoch 79/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3914\n",
      "Epoch 80/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3909\n",
      "Epoch 81/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3916\n",
      "Epoch 82/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3963\n",
      "Epoch 83/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3800\n",
      "Epoch 84/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3787\n",
      "Epoch 85/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3823\n",
      "Epoch 86/1000\n",
      "93/93 [==============================] - 0s 258us/step - loss: 0.3835\n",
      "Epoch 87/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3919\n",
      "Epoch 88/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3975\n",
      "Epoch 89/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3791\n",
      "Epoch 90/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3970\n",
      "Epoch 91/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3858\n",
      "Epoch 92/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3827\n",
      "Epoch 93/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3796\n",
      "Epoch 94/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3809\n",
      "Epoch 95/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3807\n",
      "Epoch 96/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3921\n",
      "Epoch 97/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3958\n",
      "Epoch 98/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3892\n",
      "Epoch 99/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3787\n",
      "Epoch 100/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3944\n",
      "Epoch 101/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3904\n",
      "Epoch 102/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3802\n",
      "Epoch 103/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3872\n",
      "Epoch 104/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3810\n",
      "Epoch 105/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3987\n",
      "Epoch 106/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3838\n",
      "Epoch 107/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3905\n",
      "Epoch 108/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3968\n",
      "Epoch 109/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.4027\n",
      "Epoch 110/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3892\n",
      "Epoch 111/1000\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.3802\n",
      "Epoch 112/1000\n",
      "93/93 [==============================] - 0s 307us/step - loss: 0.3802\n",
      "Epoch 113/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.3817\n",
      "Epoch 114/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3828\n",
      "Epoch 115/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3876\n",
      "Epoch 116/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3783\n",
      "Epoch 117/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3861\n",
      "Epoch 118/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3730\n",
      "Epoch 119/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3852\n",
      "Epoch 120/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3901\n",
      "Epoch 121/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3860\n",
      "Epoch 122/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3863\n",
      "Epoch 123/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3742\n",
      "Epoch 124/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3763\n",
      "Epoch 125/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.4046\n",
      "Epoch 126/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3870\n",
      "Epoch 127/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3934\n",
      "Epoch 128/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3935\n",
      "Epoch 129/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3906\n",
      "Epoch 130/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3856\n",
      "Epoch 131/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3831\n",
      "Epoch 132/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3809\n",
      "Epoch 133/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3785\n",
      "Epoch 134/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3799\n",
      "Epoch 135/1000\n",
      "93/93 [==============================] - 0s 242us/step - loss: 0.3737\n",
      "Epoch 136/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3849\n",
      "Epoch 137/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3828\n",
      "Epoch 138/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3621\n",
      "Epoch 139/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3937\n",
      "Epoch 140/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3755\n",
      "Epoch 141/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3894\n",
      "Epoch 142/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3720\n",
      "Epoch 143/1000\n",
      "93/93 [==============================] - 0s 266us/step - loss: 0.3873\n",
      "Epoch 144/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3900\n",
      "Epoch 145/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3748\n",
      "Epoch 146/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3884\n",
      "Epoch 147/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3724\n",
      "Epoch 148/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3865\n",
      "Epoch 149/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3808\n",
      "Epoch 150/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3851\n",
      "Epoch 151/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3934\n",
      "Epoch 152/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3805\n",
      "Epoch 153/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3769\n",
      "Epoch 154/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3804\n",
      "Epoch 155/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3741\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 302us/step - loss: 0.3755\n",
      "Epoch 157/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3807\n",
      "Epoch 158/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3833\n",
      "Epoch 159/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3740\n",
      "Epoch 160/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3835\n",
      "Epoch 161/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3955\n",
      "Epoch 162/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3904\n",
      "Epoch 163/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3975\n",
      "Epoch 164/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3879\n",
      "Epoch 165/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3683\n",
      "Epoch 166/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3827\n",
      "Epoch 167/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3633\n",
      "Epoch 168/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3857\n",
      "Epoch 169/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3914\n",
      "Epoch 170/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3826\n",
      "Epoch 171/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3862\n",
      "Epoch 172/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3879\n",
      "Epoch 173/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3783\n",
      "Epoch 174/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3812\n",
      "Epoch 175/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3770\n",
      "Epoch 176/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3844\n",
      "Epoch 177/1000\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.3869\n",
      "Epoch 178/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3771\n",
      "Epoch 179/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3803\n",
      "Epoch 180/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3920\n",
      "Epoch 181/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3874\n",
      "Epoch 182/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3725\n",
      "Epoch 183/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3661\n",
      "Epoch 184/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3941\n",
      "Epoch 185/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3735\n",
      "Epoch 186/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3735\n",
      "Epoch 187/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3821\n",
      "Epoch 188/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3891\n",
      "Epoch 189/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3816\n",
      "Epoch 190/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3944\n",
      "Epoch 191/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3812\n",
      "Epoch 192/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3825\n",
      "Epoch 193/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3795\n",
      "Epoch 194/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3718\n",
      "Epoch 195/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.4030\n",
      "Epoch 196/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3766\n",
      "Epoch 197/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3658\n",
      "Epoch 198/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3809\n",
      "Epoch 199/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3813\n",
      "Epoch 200/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3770\n",
      "Epoch 201/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3787\n",
      "Epoch 202/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3839\n",
      "Epoch 203/1000\n",
      "93/93 [==============================] - 0s 238us/step - loss: 0.3795\n",
      "Epoch 204/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3892\n",
      "Epoch 205/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3739\n",
      "Epoch 206/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3696\n",
      "Epoch 207/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3781\n",
      "Epoch 208/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3692\n",
      "Epoch 209/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3725\n",
      "Epoch 210/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3788\n",
      "Epoch 211/1000\n",
      "93/93 [==============================] - 0s 250us/step - loss: 0.3758\n",
      "Epoch 212/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3751\n",
      "Epoch 213/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3686\n",
      "Epoch 214/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3773\n",
      "Epoch 215/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3809\n",
      "Epoch 216/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3889\n",
      "Epoch 217/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3710\n",
      "Epoch 218/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3745\n",
      "Epoch 219/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3690\n",
      "Epoch 220/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3716\n",
      "Epoch 221/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.325 - 0s 259us/step - loss: 0.3799\n",
      "Epoch 222/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3735\n",
      "Epoch 223/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3898\n",
      "Epoch 224/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3921\n",
      "Epoch 225/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3719\n",
      "Epoch 226/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3801\n",
      "Epoch 227/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3686\n",
      "Epoch 228/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3802\n",
      "Epoch 229/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3752\n",
      "Epoch 230/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3770\n",
      "Epoch 231/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3683\n",
      "Epoch 232/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3765\n",
      "Epoch 233/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3643\n",
      "Epoch 234/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3786\n",
      "Epoch 235/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3751\n",
      "Epoch 236/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3888\n",
      "Epoch 237/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3737\n",
      "Epoch 238/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3695\n",
      "Epoch 239/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3813\n",
      "Epoch 240/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3819\n",
      "Epoch 241/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3803\n",
      "Epoch 242/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3710\n",
      "Epoch 243/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3702\n",
      "Epoch 244/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3598\n",
      "Epoch 245/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3725\n",
      "Epoch 246/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3702\n",
      "Epoch 247/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3838\n",
      "Epoch 248/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3729\n",
      "Epoch 249/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3714\n",
      "Epoch 250/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3711\n",
      "Epoch 251/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3754\n",
      "Epoch 252/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3700\n",
      "Epoch 253/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3750\n",
      "Epoch 254/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3722\n",
      "Epoch 255/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3706\n",
      "Epoch 256/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3854\n",
      "Epoch 257/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3682\n",
      "Epoch 258/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3734\n",
      "Epoch 259/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3745\n",
      "Epoch 260/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3804\n",
      "Epoch 261/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3637\n",
      "Epoch 262/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3702\n",
      "Epoch 263/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3779\n",
      "Epoch 264/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3642\n",
      "Epoch 265/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3567\n",
      "Epoch 266/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3630\n",
      "Epoch 267/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3777\n",
      "Epoch 268/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3662\n",
      "Epoch 269/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3641\n",
      "Epoch 270/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3746\n",
      "Epoch 271/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3557\n",
      "Epoch 272/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3699\n",
      "Epoch 273/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3558\n",
      "Epoch 274/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3609\n",
      "Epoch 275/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3643\n",
      "Epoch 276/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3642\n",
      "Epoch 277/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3632\n",
      "Epoch 278/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3706\n",
      "Epoch 279/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3718\n",
      "Epoch 280/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3673\n",
      "Epoch 281/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3808\n",
      "Epoch 282/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3730\n",
      "Epoch 283/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3744\n",
      "Epoch 284/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3663\n",
      "Epoch 285/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3725\n",
      "Epoch 286/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3487\n",
      "Epoch 287/1000\n",
      "93/93 [==============================] - 0s 267us/step - loss: 0.3681\n",
      "Epoch 288/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3656\n",
      "Epoch 289/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3579\n",
      "Epoch 290/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3773\n",
      "Epoch 291/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3521\n",
      "Epoch 292/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3598\n",
      "Epoch 293/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3883\n",
      "Epoch 294/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3555\n",
      "Epoch 295/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3590\n",
      "Epoch 296/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3664\n",
      "Epoch 297/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3709\n",
      "Epoch 298/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3776\n",
      "Epoch 299/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3537\n",
      "Epoch 300/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3566\n",
      "Epoch 301/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3567\n",
      "Epoch 302/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.307 - 0s 232us/step - loss: 0.3712\n",
      "Epoch 303/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3713\n",
      "Epoch 304/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3575\n",
      "Epoch 305/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3690\n",
      "Epoch 306/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3868\n",
      "Epoch 307/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3674\n",
      "Epoch 308/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3670\n",
      "Epoch 309/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3618\n",
      "Epoch 310/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3685\n",
      "Epoch 311/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3708\n",
      "Epoch 312/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3634\n",
      "Epoch 313/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3656\n",
      "Epoch 314/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3717\n",
      "Epoch 315/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3578\n",
      "Epoch 316/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3664\n",
      "Epoch 317/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3632\n",
      "Epoch 318/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3734\n",
      "Epoch 319/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3616\n",
      "Epoch 320/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3577\n",
      "Epoch 321/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3627\n",
      "Epoch 322/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3624\n",
      "Epoch 323/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3574\n",
      "Epoch 324/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3644\n",
      "Epoch 325/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3787\n",
      "Epoch 326/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3702\n",
      "Epoch 327/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3680\n",
      "Epoch 328/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3681\n",
      "Epoch 329/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3586\n",
      "Epoch 330/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3541\n",
      "Epoch 331/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3730\n",
      "Epoch 332/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3591\n",
      "Epoch 333/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3629\n",
      "Epoch 334/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3624\n",
      "Epoch 335/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3625\n",
      "Epoch 336/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3588\n",
      "Epoch 337/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3830\n",
      "Epoch 338/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3608\n",
      "Epoch 339/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3649\n",
      "Epoch 340/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3626\n",
      "Epoch 341/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3757\n",
      "Epoch 342/1000\n",
      "93/93 [==============================] - 0s 273us/step - loss: 0.3734\n",
      "Epoch 343/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3563\n",
      "Epoch 344/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3627\n",
      "Epoch 345/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3564\n",
      "Epoch 346/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3842\n",
      "Epoch 347/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3586\n",
      "Epoch 348/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 280us/step - loss: 0.3655\n",
      "Epoch 349/1000\n",
      "93/93 [==============================] - 0s 254us/step - loss: 0.3752\n",
      "Epoch 350/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3745\n",
      "Epoch 351/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3611\n",
      "Epoch 352/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3699\n",
      "Epoch 353/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3673\n",
      "Epoch 354/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3607\n",
      "Epoch 355/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3742\n",
      "Epoch 356/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3604\n",
      "Epoch 357/1000\n",
      "93/93 [==============================] - 0s 281us/step - loss: 0.3670\n",
      "Epoch 358/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3629\n",
      "Epoch 359/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3646\n",
      "Epoch 360/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3611\n",
      "Epoch 361/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3592\n",
      "Epoch 362/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3573\n",
      "Epoch 363/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.309 - 0s 237us/step - loss: 0.3700\n",
      "Epoch 364/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3652\n",
      "Epoch 365/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3670\n",
      "Epoch 366/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3714\n",
      "Epoch 367/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3656\n",
      "Epoch 368/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3561\n",
      "Epoch 369/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3684\n",
      "Epoch 370/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3611\n",
      "Epoch 371/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3480\n",
      "Epoch 372/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3659\n",
      "Epoch 373/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3703\n",
      "Epoch 374/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3659\n",
      "Epoch 375/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3563\n",
      "Epoch 376/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3567\n",
      "Epoch 377/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3633\n",
      "Epoch 378/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3528\n",
      "Epoch 379/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3581\n",
      "Epoch 380/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3671\n",
      "Epoch 381/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3610\n",
      "Epoch 382/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.3507\n",
      "Epoch 383/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3649\n",
      "Epoch 384/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3754\n",
      "Epoch 385/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3720\n",
      "Epoch 386/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3538\n",
      "Epoch 387/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3515\n",
      "Epoch 388/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3673\n",
      "Epoch 389/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3631\n",
      "Epoch 390/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3623\n",
      "Epoch 391/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3583\n",
      "Epoch 392/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3470\n",
      "Epoch 393/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3638\n",
      "Epoch 394/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3675\n",
      "Epoch 395/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3644\n",
      "Epoch 396/1000\n",
      "93/93 [==============================] - 0s 356us/step - loss: 0.3546\n",
      "Epoch 397/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3598\n",
      "Epoch 398/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3602\n",
      "Epoch 399/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3667\n",
      "Epoch 400/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3566\n",
      "Epoch 401/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3668\n",
      "Epoch 402/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3578\n",
      "Epoch 403/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3727\n",
      "Epoch 404/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3524\n",
      "Epoch 405/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3509\n",
      "Epoch 406/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3685\n",
      "Epoch 407/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3634\n",
      "Epoch 408/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3609\n",
      "Epoch 409/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3710\n",
      "Epoch 410/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3718\n",
      "Epoch 411/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3672\n",
      "Epoch 412/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3568\n",
      "Epoch 413/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3625\n",
      "Epoch 414/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3585\n",
      "Epoch 415/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3661\n",
      "Epoch 416/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3641\n",
      "Epoch 417/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3653\n",
      "Epoch 418/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3560\n",
      "Epoch 419/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3528\n",
      "Epoch 420/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3660\n",
      "Epoch 421/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3583\n",
      "Epoch 422/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3497\n",
      "Epoch 423/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3562\n",
      "Epoch 424/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3575\n",
      "Epoch 425/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3590\n",
      "Epoch 426/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3477\n",
      "Epoch 427/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3518\n",
      "Epoch 428/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3660\n",
      "Epoch 429/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3710\n",
      "Epoch 430/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3652\n",
      "Epoch 431/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3574\n",
      "Epoch 432/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3649\n",
      "Epoch 433/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3591\n",
      "Epoch 434/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3503\n",
      "Epoch 435/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3560\n",
      "Epoch 436/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3571\n",
      "Epoch 437/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3693\n",
      "Epoch 438/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3585\n",
      "Epoch 439/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3472\n",
      "Epoch 440/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3600\n",
      "Epoch 441/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3583\n",
      "Epoch 442/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3470\n",
      "Epoch 443/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3700\n",
      "Epoch 444/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3540\n",
      "Epoch 445/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3419\n",
      "Epoch 446/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3616\n",
      "Epoch 447/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3516\n",
      "Epoch 448/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3538\n",
      "Epoch 449/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3670\n",
      "Epoch 450/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3600\n",
      "Epoch 451/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3618\n",
      "Epoch 452/1000\n",
      "93/93 [==============================] - 0s 240us/step - loss: 0.3556\n",
      "Epoch 453/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3552\n",
      "Epoch 454/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3707\n",
      "Epoch 455/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3485\n",
      "Epoch 456/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3633\n",
      "Epoch 457/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3606\n",
      "Epoch 458/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3471\n",
      "Epoch 459/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3618\n",
      "Epoch 460/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3515\n",
      "Epoch 461/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3540\n",
      "Epoch 462/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3558\n",
      "Epoch 463/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3588\n",
      "Epoch 464/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3609\n",
      "Epoch 465/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3569\n",
      "Epoch 466/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3568\n",
      "Epoch 467/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3378\n",
      "Epoch 468/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3669\n",
      "Epoch 469/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.3511\n",
      "Epoch 470/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3673\n",
      "Epoch 471/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3478\n",
      "Epoch 472/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3546\n",
      "Epoch 473/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3510\n",
      "Epoch 474/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3535\n",
      "Epoch 475/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3659\n",
      "Epoch 476/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3576\n",
      "Epoch 477/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3522\n",
      "Epoch 478/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3536\n",
      "Epoch 479/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3611\n",
      "Epoch 480/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3398\n",
      "Epoch 481/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3416\n",
      "Epoch 482/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3577\n",
      "Epoch 483/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3454\n",
      "Epoch 484/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3573\n",
      "Epoch 485/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3525\n",
      "Epoch 486/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3518\n",
      "Epoch 487/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3622\n",
      "Epoch 488/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3499\n",
      "Epoch 489/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3597\n",
      "Epoch 490/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3356\n",
      "Epoch 491/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3533\n",
      "Epoch 492/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3585\n",
      "Epoch 493/1000\n",
      "93/93 [==============================] - 0s 256us/step - loss: 0.3558\n",
      "Epoch 494/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3442\n",
      "Epoch 495/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3599\n",
      "Epoch 496/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3541\n",
      "Epoch 497/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3512\n",
      "Epoch 498/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3589\n",
      "Epoch 499/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3568\n",
      "Epoch 500/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3654\n",
      "Epoch 501/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3512\n",
      "Epoch 502/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3448\n",
      "Epoch 503/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3720\n",
      "Epoch 504/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3505\n",
      "Epoch 505/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3567\n",
      "Epoch 506/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3513\n",
      "Epoch 507/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3423\n",
      "Epoch 508/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3590\n",
      "Epoch 509/1000\n",
      "93/93 [==============================] - 0s 284us/step - loss: 0.3446\n",
      "Epoch 510/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3515\n",
      "Epoch 511/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3643\n",
      "Epoch 512/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3479\n",
      "Epoch 513/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3414\n",
      "Epoch 514/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3412\n",
      "Epoch 515/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3622\n",
      "Epoch 516/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3649\n",
      "Epoch 517/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3590\n",
      "Epoch 518/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3533\n",
      "Epoch 519/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.299 - 0s 237us/step - loss: 0.3591\n",
      "Epoch 520/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3412\n",
      "Epoch 521/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3601\n",
      "Epoch 522/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3607\n",
      "Epoch 523/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3593\n",
      "Epoch 524/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3516\n",
      "Epoch 525/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3452\n",
      "Epoch 526/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3541\n",
      "Epoch 527/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3499\n",
      "Epoch 528/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3408\n",
      "Epoch 529/1000\n",
      "93/93 [==============================] - 0s 284us/step - loss: 0.3529\n",
      "Epoch 530/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3422\n",
      "Epoch 531/1000\n",
      "93/93 [==============================] - 0s 394us/step - loss: 0.3457\n",
      "Epoch 532/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3616\n",
      "Epoch 533/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.3485\n",
      "Epoch 534/1000\n",
      "93/93 [==============================] - 0s 356us/step - loss: 0.3633\n",
      "Epoch 535/1000\n",
      "93/93 [==============================] - 0s 367us/step - loss: 0.3570\n",
      "Epoch 536/1000\n",
      "93/93 [==============================] - 0s 410us/step - loss: 0.3620\n",
      "Epoch 537/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3442\n",
      "Epoch 538/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3501\n",
      "Epoch 539/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3461\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 226us/step - loss: 0.3542\n",
      "Epoch 541/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3465\n",
      "Epoch 542/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3561\n",
      "Epoch 543/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3505\n",
      "Epoch 544/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3481\n",
      "Epoch 545/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3559\n",
      "Epoch 546/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3422\n",
      "Epoch 547/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3634\n",
      "Epoch 548/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3506\n",
      "Epoch 549/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3520\n",
      "Epoch 550/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3487\n",
      "Epoch 551/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.3526\n",
      "Epoch 552/1000\n",
      "93/93 [==============================] - 0s 324us/step - loss: 0.3452\n",
      "Epoch 553/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3366\n",
      "Epoch 554/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3585\n",
      "Epoch 555/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3441\n",
      "Epoch 556/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3492\n",
      "Epoch 557/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3592\n",
      "Epoch 558/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3353\n",
      "Epoch 559/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3463\n",
      "Epoch 560/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3629\n",
      "Epoch 561/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3460\n",
      "Epoch 562/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3642\n",
      "Epoch 563/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3531\n",
      "Epoch 564/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3465\n",
      "Epoch 565/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3501\n",
      "Epoch 566/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3553\n",
      "Epoch 567/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3564\n",
      "Epoch 568/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3488\n",
      "Epoch 569/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3567\n",
      "Epoch 570/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3462\n",
      "Epoch 571/1000\n",
      "93/93 [==============================] - 0s 340us/step - loss: 0.3401\n",
      "Epoch 572/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3401\n",
      "Epoch 573/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3456\n",
      "Epoch 574/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3551\n",
      "Epoch 575/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3525\n",
      "Epoch 576/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3421\n",
      "Epoch 577/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3353\n",
      "Epoch 578/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3433\n",
      "Epoch 579/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3455\n",
      "Epoch 580/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3502\n",
      "Epoch 581/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3419\n",
      "Epoch 582/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3600\n",
      "Epoch 583/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3322\n",
      "Epoch 584/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3565\n",
      "Epoch 585/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3411\n",
      "Epoch 586/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3402\n",
      "Epoch 587/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3390\n",
      "Epoch 588/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3365\n",
      "Epoch 589/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3423\n",
      "Epoch 590/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3549\n",
      "Epoch 591/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3385\n",
      "Epoch 592/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.282 - 0s 259us/step - loss: 0.3440\n",
      "Epoch 593/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3579\n",
      "Epoch 594/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3432\n",
      "Epoch 595/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3513\n",
      "Epoch 596/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3544\n",
      "Epoch 597/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3405\n",
      "Epoch 598/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3477\n",
      "Epoch 599/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3353\n",
      "Epoch 600/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3304\n",
      "Epoch 601/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3541\n",
      "Epoch 602/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3472\n",
      "Epoch 603/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3481\n",
      "Epoch 604/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3467\n",
      "Epoch 605/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3570\n",
      "Epoch 606/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3455\n",
      "Epoch 607/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3370\n",
      "Epoch 608/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3393\n",
      "Epoch 609/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3425\n",
      "Epoch 610/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3407\n",
      "Epoch 611/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.300 - 0s 248us/step - loss: 0.3526\n",
      "Epoch 612/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3461\n",
      "Epoch 613/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3562\n",
      "Epoch 614/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3504\n",
      "Epoch 615/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3429\n",
      "Epoch 616/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3400\n",
      "Epoch 617/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3408\n",
      "Epoch 618/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3438\n",
      "Epoch 619/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3306\n",
      "Epoch 620/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3537\n",
      "Epoch 621/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3471\n",
      "Epoch 622/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3403\n",
      "Epoch 623/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3324\n",
      "Epoch 624/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3424\n",
      "Epoch 625/1000\n",
      "93/93 [==============================] - 0s 210us/step - loss: 0.3398\n",
      "Epoch 626/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3421\n",
      "Epoch 627/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3465\n",
      "Epoch 628/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3483\n",
      "Epoch 629/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3467\n",
      "Epoch 630/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3487\n",
      "Epoch 631/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.283 - 0s 237us/step - loss: 0.3404\n",
      "Epoch 632/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3369\n",
      "Epoch 633/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3391\n",
      "Epoch 634/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3503\n",
      "Epoch 635/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3569\n",
      "Epoch 636/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3363\n",
      "Epoch 637/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3349\n",
      "Epoch 638/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3469\n",
      "Epoch 639/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3468\n",
      "Epoch 640/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3394\n",
      "Epoch 641/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3453\n",
      "Epoch 642/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3398\n",
      "Epoch 643/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3510\n",
      "Epoch 644/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3308\n",
      "Epoch 645/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3414\n",
      "Epoch 646/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3424\n",
      "Epoch 647/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3467\n",
      "Epoch 648/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3329\n",
      "Epoch 649/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3475\n",
      "Epoch 650/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3391\n",
      "Epoch 651/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3299\n",
      "Epoch 652/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3322\n",
      "Epoch 653/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3369\n",
      "Epoch 654/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3488\n",
      "Epoch 655/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3418\n",
      "Epoch 656/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3438\n",
      "Epoch 657/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3357\n",
      "Epoch 658/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3432\n",
      "Epoch 659/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3510\n",
      "Epoch 660/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3532\n",
      "Epoch 661/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3436\n",
      "Epoch 662/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3360\n",
      "Epoch 663/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3307\n",
      "Epoch 664/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3470\n",
      "Epoch 665/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3395\n",
      "Epoch 666/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3451\n",
      "Epoch 667/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3407\n",
      "Epoch 668/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3421\n",
      "Epoch 669/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3304\n",
      "Epoch 670/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3449\n",
      "Epoch 671/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3329\n",
      "Epoch 672/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3417\n",
      "Epoch 673/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3391\n",
      "Epoch 674/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3439\n",
      "Epoch 675/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3296\n",
      "Epoch 676/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3325\n",
      "Epoch 677/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3331\n",
      "Epoch 678/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3414\n",
      "Epoch 679/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3340\n",
      "Epoch 680/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3424\n",
      "Epoch 681/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3508\n",
      "Epoch 682/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3316\n",
      "Epoch 683/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3473\n",
      "Epoch 684/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3357\n",
      "Epoch 685/1000\n",
      "93/93 [==============================] - 0s 340us/step - loss: 0.3453\n",
      "Epoch 686/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3308\n",
      "Epoch 687/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3373\n",
      "Epoch 688/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3443\n",
      "Epoch 689/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.287 - 0s 243us/step - loss: 0.3458\n",
      "Epoch 690/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3316\n",
      "Epoch 691/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3380\n",
      "Epoch 692/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3385\n",
      "Epoch 693/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3421\n",
      "Epoch 694/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3398\n",
      "Epoch 695/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3539\n",
      "Epoch 696/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3297\n",
      "Epoch 697/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3311\n",
      "Epoch 698/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3382\n",
      "Epoch 699/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3491\n",
      "Epoch 700/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3408\n",
      "Epoch 701/1000\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.3347\n",
      "Epoch 702/1000\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.3412\n",
      "Epoch 703/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3356\n",
      "Epoch 704/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.3495\n",
      "Epoch 705/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3372\n",
      "Epoch 706/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3373\n",
      "Epoch 707/1000\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.3436\n",
      "Epoch 708/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3390\n",
      "Epoch 709/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3508\n",
      "Epoch 710/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3252\n",
      "Epoch 711/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3333\n",
      "Epoch 712/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3571\n",
      "Epoch 713/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3341\n",
      "Epoch 714/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3424\n",
      "Epoch 715/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3379\n",
      "Epoch 716/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3131\n",
      "Epoch 717/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3414\n",
      "Epoch 718/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3408\n",
      "Epoch 719/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3540\n",
      "Epoch 720/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3455\n",
      "Epoch 721/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3385\n",
      "Epoch 722/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3334\n",
      "Epoch 723/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3471\n",
      "Epoch 724/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3369\n",
      "Epoch 725/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3266\n",
      "Epoch 726/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3272\n",
      "Epoch 727/1000\n",
      "93/93 [==============================] - 0s 245us/step - loss: 0.3417\n",
      "Epoch 728/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3293\n",
      "Epoch 729/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3252\n",
      "Epoch 730/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3396\n",
      "Epoch 731/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 244us/step - loss: 0.3384\n",
      "Epoch 732/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3521\n",
      "Epoch 733/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3410\n",
      "Epoch 734/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3336\n",
      "Epoch 735/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3342\n",
      "Epoch 736/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3350\n",
      "Epoch 737/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3315\n",
      "Epoch 738/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3399\n",
      "Epoch 739/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3267\n",
      "Epoch 740/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3397\n",
      "Epoch 741/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3348\n",
      "Epoch 742/1000\n",
      "93/93 [==============================] - 0s 307us/step - loss: 0.3306\n",
      "Epoch 743/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3445\n",
      "Epoch 744/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3324\n",
      "Epoch 745/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3408\n",
      "Epoch 746/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3356\n",
      "Epoch 747/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3438\n",
      "Epoch 748/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3298\n",
      "Epoch 749/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3342\n",
      "Epoch 750/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3393\n",
      "Epoch 751/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3285\n",
      "Epoch 752/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3344\n",
      "Epoch 753/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3395\n",
      "Epoch 754/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3346\n",
      "Epoch 755/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3443\n",
      "Epoch 756/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3364\n",
      "Epoch 757/1000\n",
      "93/93 [==============================] - 0s 231us/step - loss: 0.3226\n",
      "Epoch 758/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3314\n",
      "Epoch 759/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3392\n",
      "Epoch 760/1000\n",
      "93/93 [==============================] - 0s 307us/step - loss: 0.3402\n",
      "Epoch 761/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3387\n",
      "Epoch 762/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3309\n",
      "Epoch 763/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3381\n",
      "Epoch 764/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3269\n",
      "Epoch 765/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3319\n",
      "Epoch 766/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3303\n",
      "Epoch 767/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3290\n",
      "Epoch 768/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3364\n",
      "Epoch 769/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3372\n",
      "Epoch 770/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3368\n",
      "Epoch 771/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3257\n",
      "Epoch 772/1000\n",
      "93/93 [==============================] - 0s 231us/step - loss: 0.3390\n",
      "Epoch 773/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3329\n",
      "Epoch 774/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3366\n",
      "Epoch 775/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3528\n",
      "Epoch 776/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3332\n",
      "Epoch 777/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3347\n",
      "Epoch 778/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3358\n",
      "Epoch 779/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3305\n",
      "Epoch 780/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3329\n",
      "Epoch 781/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3303\n",
      "Epoch 782/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3384\n",
      "Epoch 783/1000\n",
      "93/93 [==============================] - 0s 250us/step - loss: 0.3259\n",
      "Epoch 784/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3239\n",
      "Epoch 785/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3276\n",
      "Epoch 786/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3316\n",
      "Epoch 787/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3359\n",
      "Epoch 788/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3338\n",
      "Epoch 789/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3337\n",
      "Epoch 790/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3412\n",
      "Epoch 791/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3351\n",
      "Epoch 792/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3285\n",
      "Epoch 793/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3320\n",
      "Epoch 794/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3321\n",
      "Epoch 795/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3365\n",
      "Epoch 796/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3299\n",
      "Epoch 797/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3309\n",
      "Epoch 798/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3425\n",
      "Epoch 799/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3244\n",
      "Epoch 800/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3403\n",
      "Epoch 801/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3276\n",
      "Epoch 802/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3285\n",
      "Epoch 803/1000\n",
      "93/93 [==============================] - 0s 205us/step - loss: 0.3417\n",
      "Epoch 804/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3230\n",
      "Epoch 805/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3323\n",
      "Epoch 806/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3370\n",
      "Epoch 807/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3355\n",
      "Epoch 808/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3480\n",
      "Epoch 809/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3336\n",
      "Epoch 810/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3309\n",
      "Epoch 811/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3346\n",
      "Epoch 812/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3167\n",
      "Epoch 813/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3308\n",
      "Epoch 814/1000\n",
      "93/93 [==============================] - 0s 217us/step - loss: 0.3405\n",
      "Epoch 815/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3325\n",
      "Epoch 816/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3338\n",
      "Epoch 817/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3324\n",
      "Epoch 818/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3306\n",
      "Epoch 819/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3322\n",
      "Epoch 820/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3239\n",
      "Epoch 821/1000\n",
      "93/93 [==============================] - 0s 245us/step - loss: 0.3383\n",
      "Epoch 822/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3428\n",
      "Epoch 823/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3358\n",
      "Epoch 824/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3391\n",
      "Epoch 825/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3339\n",
      "Epoch 826/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3290\n",
      "Epoch 827/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3254\n",
      "Epoch 828/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3197\n",
      "Epoch 829/1000\n",
      "93/93 [==============================] - 0s 281us/step - loss: 0.3305\n",
      "Epoch 830/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3427\n",
      "Epoch 831/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3254\n",
      "Epoch 832/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3280\n",
      "Epoch 833/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3330\n",
      "Epoch 834/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3315\n",
      "Epoch 835/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3152\n",
      "Epoch 836/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.3532\n",
      "Epoch 837/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3433\n",
      "Epoch 838/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3364\n",
      "Epoch 839/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3345\n",
      "Epoch 840/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3325\n",
      "Epoch 841/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3276\n",
      "Epoch 842/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3243\n",
      "Epoch 843/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3324\n",
      "Epoch 844/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3267\n",
      "Epoch 845/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3353\n",
      "Epoch 846/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3354\n",
      "Epoch 847/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3223\n",
      "Epoch 848/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3327\n",
      "Epoch 849/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3271\n",
      "Epoch 850/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3370\n",
      "Epoch 851/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3355\n",
      "Epoch 852/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3302\n",
      "Epoch 853/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3375\n",
      "Epoch 854/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3348\n",
      "Epoch 855/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3277\n",
      "Epoch 856/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3288\n",
      "Epoch 857/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3337\n",
      "Epoch 858/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3252\n",
      "Epoch 859/1000\n",
      "93/93 [==============================] - 0s 249us/step - loss: 0.3244\n",
      "Epoch 860/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3292\n",
      "Epoch 861/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3309\n",
      "Epoch 862/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3286\n",
      "Epoch 863/1000\n",
      "93/93 [==============================] - 0s 252us/step - loss: 0.3236\n",
      "Epoch 864/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3299\n",
      "Epoch 865/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3416\n",
      "Epoch 866/1000\n",
      "93/93 [==============================] - 0s 253us/step - loss: 0.3287\n",
      "Epoch 867/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3198\n",
      "Epoch 868/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3341\n",
      "Epoch 869/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3340\n",
      "Epoch 870/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3133\n",
      "Epoch 871/1000\n",
      "93/93 [==============================] - 0s 276us/step - loss: 0.3341\n",
      "Epoch 872/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3237\n",
      "Epoch 873/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3302\n",
      "Epoch 874/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3145\n",
      "Epoch 875/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3311\n",
      "Epoch 876/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3317\n",
      "Epoch 877/1000\n",
      "93/93 [==============================] - 0s 302us/step - loss: 0.3271\n",
      "Epoch 878/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3198\n",
      "Epoch 879/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3244\n",
      "Epoch 880/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3265\n",
      "Epoch 881/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3291\n",
      "Epoch 882/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3388\n",
      "Epoch 883/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3198\n",
      "Epoch 884/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3179\n",
      "Epoch 885/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.289 - 0s 270us/step - loss: 0.3390\n",
      "Epoch 886/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3177\n",
      "Epoch 887/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3190\n",
      "Epoch 888/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3328\n",
      "Epoch 889/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3252\n",
      "Epoch 890/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3228\n",
      "Epoch 891/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3303\n",
      "Epoch 892/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3245\n",
      "Epoch 893/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3266\n",
      "Epoch 894/1000\n",
      "93/93 [==============================] - 0s 297us/step - loss: 0.3223\n",
      "Epoch 895/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3334\n",
      "Epoch 896/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3189\n",
      "Epoch 897/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3429\n",
      "Epoch 898/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3385\n",
      "Epoch 899/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3249\n",
      "Epoch 900/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3193\n",
      "Epoch 901/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3120\n",
      "Epoch 902/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3182\n",
      "Epoch 903/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3339\n",
      "Epoch 904/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3173\n",
      "Epoch 905/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3151\n",
      "Epoch 906/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3315\n",
      "Epoch 907/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3312\n",
      "Epoch 908/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3226\n",
      "Epoch 909/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3215\n",
      "Epoch 910/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3299\n",
      "Epoch 911/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3220\n",
      "Epoch 912/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3258\n",
      "Epoch 913/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3390\n",
      "Epoch 914/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3243\n",
      "Epoch 915/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3295\n",
      "Epoch 916/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3370\n",
      "Epoch 917/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3219\n",
      "Epoch 918/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3094\n",
      "Epoch 919/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3310\n",
      "Epoch 920/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3243\n",
      "Epoch 921/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3283\n",
      "Epoch 922/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3309\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 248us/step - loss: 0.3355\n",
      "Epoch 924/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3149\n",
      "Epoch 925/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3139\n",
      "Epoch 926/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3326\n",
      "Epoch 927/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3235\n",
      "Epoch 928/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3323\n",
      "Epoch 929/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3153\n",
      "Epoch 930/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3293\n",
      "Epoch 931/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3178\n",
      "Epoch 932/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3196\n",
      "Epoch 933/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3173\n",
      "Epoch 934/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3309\n",
      "Epoch 935/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3303\n",
      "Epoch 936/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3224\n",
      "Epoch 937/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3212\n",
      "Epoch 938/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3210\n",
      "Epoch 939/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3254\n",
      "Epoch 940/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3270\n",
      "Epoch 941/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3210\n",
      "Epoch 942/1000\n",
      "93/93 [==============================] - 0s 307us/step - loss: 0.3233\n",
      "Epoch 943/1000\n",
      "93/93 [==============================] - 0s 232us/step - loss: 0.3366\n",
      "Epoch 944/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3107\n",
      "Epoch 945/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3171\n",
      "Epoch 946/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3241\n",
      "Epoch 947/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3195\n",
      "Epoch 948/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3158\n",
      "Epoch 949/1000\n",
      "93/93 [==============================] - 0s 345us/step - loss: 0.3388\n",
      "Epoch 950/1000\n",
      "93/93 [==============================] - 0s 313us/step - loss: 0.3341\n",
      "Epoch 951/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3145\n",
      "Epoch 952/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3151\n",
      "Epoch 953/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3112\n",
      "Epoch 954/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3299\n",
      "Epoch 955/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3261\n",
      "Epoch 956/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3179\n",
      "Epoch 957/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3235\n",
      "Epoch 958/1000\n",
      "93/93 [==============================] - 0s 242us/step - loss: 0.3195\n",
      "Epoch 959/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3194\n",
      "Epoch 960/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3117\n",
      "Epoch 961/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3221\n",
      "Epoch 962/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3218\n",
      "Epoch 963/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3189\n",
      "Epoch 964/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3219\n",
      "Epoch 965/1000\n",
      "93/93 [==============================] - 0s 264us/step - loss: 0.3406\n",
      "Epoch 966/1000\n",
      "93/93 [==============================] - 0s 286us/step - loss: 0.3206\n",
      "Epoch 967/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3123\n",
      "Epoch 968/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3160\n",
      "Epoch 969/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3176\n",
      "Epoch 970/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3364\n",
      "Epoch 971/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3268\n",
      "Epoch 972/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3415\n",
      "Epoch 973/1000\n",
      "93/93 [==============================] - 0s 287us/step - loss: 0.3072\n",
      "Epoch 974/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3190\n",
      "Epoch 975/1000\n",
      "93/93 [==============================] - 0s 237us/step - loss: 0.3269\n",
      "Epoch 976/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3132\n",
      "Epoch 977/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3265\n",
      "Epoch 978/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3305\n",
      "Epoch 979/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3110\n",
      "Epoch 980/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3242\n",
      "Epoch 981/1000\n",
      "93/93 [==============================] - 0s 243us/step - loss: 0.3255\n",
      "Epoch 982/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3156\n",
      "Epoch 983/1000\n",
      "93/93 [==============================] - 0s 248us/step - loss: 0.3144\n",
      "Epoch 984/1000\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.3104\n",
      "Epoch 985/1000\n",
      "93/93 [==============================] - 0s 269us/step - loss: 0.3166\n",
      "Epoch 986/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3224\n",
      "Epoch 987/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3225\n",
      "Epoch 988/1000\n",
      "93/93 [==============================] - 0s 324us/step - loss: 0.3049\n",
      "Epoch 989/1000\n",
      "93/93 [==============================] - 0s 291us/step - loss: 0.3192\n",
      "Epoch 990/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3132\n",
      "Epoch 991/1000\n",
      "93/93 [==============================] - 0s 226us/step - loss: 0.3149\n",
      "Epoch 992/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3104\n",
      "Epoch 993/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3135\n",
      "Epoch 994/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3232\n",
      "Epoch 995/1000\n",
      "93/93 [==============================] - 0s 280us/step - loss: 0.3193\n",
      "Epoch 996/1000\n",
      "93/93 [==============================] - 0s 262us/step - loss: 0.3307\n",
      "Epoch 997/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3200\n",
      "Epoch 998/1000\n",
      "93/93 [==============================] - 0s 259us/step - loss: 0.3238\n",
      "Epoch 999/1000\n",
      "93/93 [==============================] - 0s 270us/step - loss: 0.3257\n",
      "Epoch 1000/1000\n",
      "93/93 [==============================] - 0s 221us/step - loss: 0.3114\n",
      "0.1671964\n"
     ]
    }
   ],
   "source": [
    "model=creat_model(11,12)\n",
    "for i in range(2):\n",
    "    model.fit(X_,Y,epochs=1000,sample_weight=sampleweights,shuffle=False)\n",
    "loss2=model.test_on_batch(X_test,y_test,sample_weight=sampleweights[sample_index])\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "test=np.array(model.predict(trylist))\n",
    "initial=test[0,0,0]\n",
    "bias=[]\n",
    "plot_x=np.linspace(0.1,40,num=400)\n",
    "margin2=np.zeros((12,400))\n",
    "for j in range(400):\n",
    "  value=plot_x[j]\n",
    "  for i in range(12):\n",
    "    trylist=np.zeros((1,20,12))\n",
    "    trylist[0,0,i]=value\n",
    "    test=np.array(model.predict(trylist))[0,0,0]\n",
    "    margin2[i,j]=test-initial\n",
    "    if j==0:\n",
    "        bias.append(margin2[i,j])\n",
    "    margin2[i,j]-=bias[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943989177544912"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bias+initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "\n",
    "py.sign_in('juniorzhu', '2DYGYXxF5dqnhzYH2CP9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]   [ (1,2) x2,y1 ]   [ (1,3) x3,y1 ]   [ (1,4) x4,y1 ] \n",
      "[ (2,1) x5,y2 ]   [ (2,2) x6,y2 ]   [ (2,3) x7,y2 ]   [ (2,4) x8,y2 ] \n",
      "[ (3,1) x9,y3 ]   [ (3,2) x10,y3 ]  [ (3,3) x11,y3 ]  [ (3,4) x12,y3 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~JuniorZhu/99.embed\" height=\"800px\" width=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1=go.Scatter(x=plot_x,y=margin2[0],mode='line',name='parameter1')\n",
    "trace2=go.Scatter(x=plot_x,y=margin2[1],mode='line',name='parameter2')\n",
    "trace3=go.Scatter(x=plot_x,y=margin2[2],mode='line',name='parameter3')\n",
    "trace4=go.Scatter(x=plot_x,y=margin2[3],mode='line',name='parameter4')\n",
    "trace5=go.Scatter(x=plot_x,y=margin2[4],mode='line',name='parameter5')\n",
    "trace6=go.Scatter(x=plot_x,y=margin2[5],mode='line',name='parameter6')\n",
    "trace7=go.Scatter(x=plot_x,y=margin2[6],mode='line',name='parameter7')\n",
    "trace8=go.Scatter(x=plot_x,y=margin2[7],mode='line',name='parameter8')\n",
    "trace9=go.Scatter(x=plot_x,y=margin2[8],mode='line',name='parameter9')\n",
    "trace10=go.Scatter(x=plot_x,y=margin2[9],mode='line',name='parameter10')\n",
    "trace11=go.Scatter(x=plot_x,y=margin2[10],mode='line',name='parameter11')\n",
    "trace12=go.Scatter(x=plot_x,y=margin2[11],mode='line',name='parameter12')\n",
    "\n",
    "\n",
    "fig = tools.make_subplots(rows=3, cols=4, shared_yaxes=True,horizontal_spacing=0.05,\n",
    "                          subplot_titles=('Health Science','Industrial/Information Science','Linguistics/Anthropology','Economics/Liguistics',\n",
    "                                          'Cultural Studies/Education/<br>Multidisciplinary Science','Neural/Behavioral Science','Communication','Psychology',\n",
    "                                          'Business','Political Science','Sociology','Inherent Interdisciplinarity'))\n",
    "\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig.append_trace(trace3, 1, 3)\n",
    "fig.append_trace(trace4, 1, 4)\n",
    "fig.append_trace(trace5, 2, 1)\n",
    "fig.append_trace(trace6, 2, 2)\n",
    "fig.append_trace(trace7, 2, 3)\n",
    "fig.append_trace(trace8, 2, 4)\n",
    "fig.append_trace(trace9, 3, 1)\n",
    "fig.append_trace(trace10, 3, 2)\n",
    "fig.append_trace(trace11, 3, 3)\n",
    "fig.append_trace(trace12, 3, 4)\n",
    "\n",
    "fig['layout'].update(height=800, width=1000,\n",
    "                     showlegend=False)\n",
    "\n",
    "py.iplot(fig,filename='parameters3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "test=np.array(model.predict(trylist))\n",
    "initial=test[0,0,0]\n",
    "plot_x=np.linspace(0,1,num=10)\n",
    "margin3=np.zeros((12,10))\n",
    "for j in range(10):\n",
    "  value=plot_x[j]\n",
    "  for i in range(12):\n",
    "    trylist=np.zeros((1,20,12))\n",
    "    trylist[0,0,i]=value\n",
    "    test=np.array(model.predict(trylist))[0,0,0]\n",
    "    margin2[i,j]=test-initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589,\n",
       "       1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589,\n",
       "       1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589, 1.2815589,\n",
       "       1.2815589, 1.2815589], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "initial=np.array(model.predict(trylist))\n",
    "initial.reshape(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24302685"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "trylist[0,0,1]=1\n",
    "np.array(model.predict(trylist)-initial)[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26604903"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "trylist[0,0,2]=1\n",
    "base=np.array(model.predict(trylist)-initial)[0,0,0]\n",
    "trylist[0,0,1]=2\n",
    "np.array(model.predict(trylist)-initial)[0,0,0]-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.05949502,  0.1518837 ,  0.20542566, -0.4587431 ,  0.19945806,\n",
       "         -0.08049555,  0.01153198, -0.16438873,  0.02952621,  0.05108555],\n",
       "        [ 0.0750453 , -0.08227262,  0.00212301, -0.13868104, -0.09239726,\n",
       "          0.5353181 ,  0.16866581,  0.69532037,  0.12823988,  0.21150148],\n",
       "        [ 0.3681382 ,  0.24668907, -0.17933212, -0.33824295, -0.4780235 ,\n",
       "         -0.30053362,  0.04874752, -0.07858804, -0.1384899 , -0.37501827],\n",
       "        [-0.416914  , -0.20224287,  0.12725815,  0.07982407, -0.40773693,\n",
       "         -0.04527383,  0.07002135, -0.17402059,  0.42701674, -0.4418332 ],\n",
       "        [-0.38393766,  0.46302202, -0.07291288, -0.19137636,  0.03645057,\n",
       "         -0.41296786, -0.05983608, -0.8806986 ,  0.06603466, -0.35321864],\n",
       "        [-0.428999  , -0.45210606,  0.29760504,  0.29485354,  0.16061631,\n",
       "         -0.31151658,  0.51940507, -0.26084414, -0.54808706,  0.03417101],\n",
       "        [-0.08096765, -0.3606362 , -0.3830215 , -0.47385296, -0.60011005,\n",
       "         -0.18208376,  0.013751  , -0.6585696 ,  0.25007585,  0.02805322],\n",
       "        [ 0.6259066 ,  0.22894841, -0.41546464,  0.42545077, -0.45305163,\n",
       "          0.22857988,  0.6418958 ,  0.3460417 ,  0.48817748,  0.40919334],\n",
       "        [-0.18063337, -0.22031374, -0.40385398,  0.02966267,  0.33386287,\n",
       "          0.25661847,  0.37869745,  0.7720747 , -0.4071676 ,  0.27355117],\n",
       "        [-0.01925218,  0.36496475, -0.31378368, -0.5145996 , -0.08802276,\n",
       "         -0.10239272, -0.20769997, -0.31369507,  0.35501447, -0.69766927],\n",
       "        [-0.8456714 ,  0.03899647,  0.48747513,  0.3642396 , -0.22281685,\n",
       "         -0.7912988 , -0.36768857, -0.5850984 ,  0.638447  , -0.76318467]],\n",
       "       dtype=float32),\n",
       " array([-0.12140235, -0.05456249, -0.08424726, -0.00487682, -0.03792278,\n",
       "        -0.21616706, -0.17895226, -0.3660297 , -0.07728813, -0.2190598 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.95089173],\n",
       "        [0.9738382 ],\n",
       "        [0.9767587 ],\n",
       "        [0.9762851 ],\n",
       "        [0.9766463 ],\n",
       "        [0.9765104 ],\n",
       "        [0.97657526],\n",
       "        [0.9765481 ],\n",
       "        [0.97656024],\n",
       "        [0.976555  ],\n",
       "        [0.9765574 ],\n",
       "        [0.9765563 ],\n",
       "        [0.9765568 ],\n",
       "        [0.97655654],\n",
       "        [0.97655666],\n",
       "        [0.97655666],\n",
       "        [0.97655666],\n",
       "        [0.97655666],\n",
       "        [0.97655666],\n",
       "        [0.97655666]]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trylist=np.zeros((1,20,12))\n",
    "trylist[0,:,10]=20\n",
    "np.array(model.predict(trylist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9588436 , 0.9588436 , 0.9588436 , 0.9588436 , 0.9588436 ,\n",
       "       0.9588436 , 0.9588436 , 0.9588436 , 0.9588436 , 0.9588436 ,\n",
       "       0.9588436 , 0.9588436 , 0.9588436 , 1.0167469 , 1.0848608 ,\n",
       "       0.9630827 , 0.9068252 , 0.8912127 , 0.74967265, 1.101134  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_[35].reshape(1,20,12)).reshape(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 1.085, 0.827, 0.94 , 0.911, 0.753,\n",
       "       1.   , 1.308])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[35].reshape(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
